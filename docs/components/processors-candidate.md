# Candidate Processors (from NiFi source)

| Type | Properties | Relationships | Annotations | Source | Description |
|------|-----------|---------------|------------|--------|-------------|
| `org.apache.nifi.amqp.processors.ConsumeAMQP` | 8 (required 6) | Auto-Acknowledge Messages, Batch Size, Header Key Prefix, Header Output Format, Header Separator, Prefetch Count, Queue, Remove Curly Braces, success | Tags: amqp, rabbit, get, message, receive, consume; WritesAttributes | nifi-extension-bundles/nifi-amqp-bundle/nifi-amqp-processors/src/main/java/org/apache/nifi/amqp/processors/ConsumeAMQP.java | Consumes AMQP Messages from an AMQP Broker using the AMQP 0.9.1 protocol. Each message that is received from the AMQP Broker will be emitted as its own FlowFile to the 'success' relationship. |
| `org.apache.nifi.amqp.processors.PublishAMQP` | 5 (required 4) | Exchange Name, Header Separator, Headers Pattern, Headers Source, Routing Key, failure, success | Tags: amqp, rabbit, put, message, send, publish; ReadsAttributes | nifi-extension-bundles/nifi-amqp-bundle/nifi-amqp-processors/src/main/java/org/apache/nifi/amqp/processors/PublishAMQP.java | Creates an AMQP Message from the contents of a FlowFile and sends the message to an AMQP Exchange. In a typical AMQP exchange model, the message that is sent to the AMQP Exchange will be routed based on the 'Routing Key' to its final destination in the queue (the binding). If due to some misconfiguration the binding between the Exchange, Routing Key and Queue is not set up, the message will have no final destination and will return (i.e., the data will not make it to the queue). If that happens you will see a log in both app-log and bulletin stating to that effect, and the FlowFile will be routed to the 'failure' relationship. |
| `org.apache.nifi.cdc.mysql.processors.CaptureChangeMySQL` | 22 (required 10) | Database/Schema Name Pattern, Distributed Map Cache Client - unused, Event Processing Strategy, Events Per FlowFile, Include Begin/Commit Events, Include DDL Events, Initial Binlog Filename, Initial Binlog GTID, Initial Binlog Position, Initial Sequence ID, Max Wait Time, MySQL Driver Class Name, MySQL Driver Location(s), MySQL Nodes, Password, Retrieve All Records, SSL Context Service, SSL Mode, Server ID, Table Name Pattern, Use Binlog GTID, Username, success | Tags: sql, jdbc, cdc, mysql, transaction, event; Restricted; Stateful; WritesAttributes | nifi-extension-bundles/nifi-cdc/nifi-cdc-mysql-bundle/nifi-cdc-mysql-processors/src/main/java/org/apache/nifi/cdc/mysql/processors/CaptureChangeMySQL.java | Retrieves Change Data Capture (CDC) events from a MySQL database. CDC Events include INSERT, UPDATE, DELETE operations. Events are output as either a group of a specified number of events (the default is 1 so each event becomes its own flow file) or grouped as a full transaction (BEGIN to COMMIT). All events are ordered by the time at which the operation occurred. NOTE: If the processor is stopped before the specified number of events have been written to a flow file, the partial flow file will be output in order to maintain the consistency of the event stream. |
| `org.apache.nifi.jms.processors.ConsumeJMS` | 11 (required 3) | Acknowledgement Mode, Durable subscription, Error Queue Name, Message Selector, Shared subscription, Subscription Name, Timeout, output-strategy, parse.failure, success | Tags: jms, get, message, receive, consume; Restricted; WritesAttributes | nifi-extension-bundles/nifi-jms-bundle/nifi-jms-processors/src/main/java/org/apache/nifi/jms/processors/ConsumeJMS.java | Consumes JMS Message of type BytesMessage, TextMessage, ObjectMessage, MapMessage or StreamMessage transforming its content to a FlowFile and transitioning it to 'success' relationship. JMS attributes such as headers and properties will be copied as FlowFile attributes. MapMessages will be transformed into JSONs and then into byte arrays. The other types will have their raw contents as byte array transferred into the flowfile. |
| `org.apache.nifi.jms.processors.PublishJMS` | 5 (required 3) | allow-illegal-chars-in-jms-header-names, attributes-to-send-as-jms-headers-regex, failure, message-body-type, success | Tags: jms, put, message, send, publish; Restricted; ReadsAttributes | nifi-extension-bundles/nifi-jms-bundle/nifi-jms-processors/src/main/java/org/apache/nifi/jms/processors/PublishJMS.java | Creates a JMS Message from the contents of a FlowFile and sends it to a JMS Destination (queue or topic) as JMS BytesMessage or TextMessage. FlowFile attributes will be added as JMS headers and/or properties to the outgoing JMS message. |
| `org.apache.nifi.kafka.processors.ConsumeKafka` | 19 (required 17) | Commit Offsets, Group ID, Header Encoding, Header Name Pattern, Kafka Connection Service, Key Attribute Encoding, Key Format, Key Record Reader, Max Uncommitted Size, Max Uncommitted Time, Message Demarcator, Output Strategy, Processing Strategy, Record Reader, Record Writer, Separate By Key, Topic Format, Topics, auto.offset.reset, parse failure, success | Tags: Kafka, Get, Record, csv, avro, json, Ingest, Ingress, Topic, PubSub, Consume; WritesAttributes | nifi-extension-bundles/nifi-kafka-bundle/nifi-kafka-processors/src/main/java/org/apache/nifi/kafka/processors/ConsumeKafka.java | Consumes messages from Apache Kafka Consumer API. The complementary NiFi processor for sending messages is PublishKafka. The Processor supports consumption of Kafka messages, optionally interpreted as NiFi records. Please note that, at this time (in read record mode), the Processor assumes that all records that are retrieved from a given partition have the same schema. For this mode, if any of the Kafka messages are pulled but cannot be parsed or written with the configured Record Reader or Record Writer, the contents of the message will be written to a separate FlowFile, and that FlowFile will be transferred to the 'parse.failure' relationship. Otherwise, each FlowFile is sent to the 'success' relationship and may contain many individual messages within the single FlowFile. A 'record.count' attribute is added to indicate how many messages are contained in the FlowFile. No two Kafka messages will be placed into the same FlowFile if they have different schemas, or if they have different values for a message header that is included by the <Headers to Add as Attributes> property. |
| `org.apache.nifi.kafka.processors.PublishKafka` | 21 (required 12) | Failure Strategy, FlowFile Attribute Header Pattern, Header Encoding, Kafka Connection Service, Kafka Key, Kafka Key Attribute Encoding, Message Demarcator, Message Key Field, Publish Strategy, Record Key Writer, Record Metadata Strategy, Record Reader, Record Writer, Topic Name, Transactional ID Prefix, Transactions Enabled, acks, compression.type, failure, max.request.size, partition, partitioner.class, success | Tags: Apache, Kafka, Record, csv, json, avro, logs, Put, Send, Message, PubSub | nifi-extension-bundles/nifi-kafka-bundle/nifi-kafka-processors/src/main/java/org/apache/nifi/kafka/processors/PublishKafka.java | Sends the contents of a FlowFile as either a message or as individual records to Apache Kafka using the Kafka Producer API. The messages to send may be individual FlowFiles, may be delimited using a user-specified delimiter (such as a new-line), or may be record-oriented data that can be read by the configured Record Reader. The complementary NiFi processor for fetching messages is ConsumeKafka. To produce a kafka tombstone message while using PublishStrategy.USE_WRAPPER, simply set the value of a record to 'null'. |
| `org.apache.nifi.processor.GhostProcessor` | 1 (required 1) |  |  | nifi-framework-bundle/nifi-framework/nifi-framework-core/src/main/java/org/apache/nifi/processor/GhostProcessor.java |  |
| `org.apache.nifi.processor.StandardProcessorInitializationContext` |  |  |  | nifi-framework-bundle/nifi-framework/nifi-framework-components/src/main/java/org/apache/nifi/processor/StandardProcessorInitializationContext.java |  |
| `org.apache.nifi.processor.util.bin.for` | 6 (required 4) | Max Bin Age, Maximum Group Size, Maximum Number of Entries, Maximum number of Bins, Minimum Group Size, Minimum Number of Entries, failure, original |  | nifi-extension-bundles/nifi-extension-utils/nifi-bin-manager/src/main/java/org/apache/nifi/processor/util/bin/BinFiles.java |  |
| `org.apache.nifi.processor.util.file.transfer.ListFileTransfer` | 5 (required 3) | Hostname, Port, Remote Path, Username |  | nifi-extension-bundles/nifi-extension-utils/nifi-file-transfer/src/main/java/org/apache/nifi/processor/util/file/transfer/ListFileTransfer.java |  |
| `org.apache.nifi.processor.util.file.transfer.for` |  | success |  | nifi-extension-bundles/nifi-extension-utils/nifi-file-transfer/src/main/java/org/apache/nifi/processor/util/file/transfer/GetFileTransfer.java |  |
| `org.apache.nifi.processors.AbstractEnrichIP` | 3 (required 3) | IP Address Attribute, Log Level, MaxMind Database File, found, not found |  | nifi-extension-bundles/nifi-enrich-bundle/nifi-enrich-processors/src/main/java/org/apache/nifi/processors/AbstractEnrichIP.java |  |
| `org.apache.nifi.processors.AbstractIoTDB` | 4 (required 4) | Host, Password, Port, Username, failure, success |  | nifi-extension-bundles/nifi-iotdb-bundle/nifi-iotdb-processors/src/main/java/org/apache/nifi/processors/AbstractIoTDB.java |  |
| `org.apache.nifi.processors.airtable.QueryAirtableTable` | 10 (required 6) | API URL, Base ID, Custom Filter, Fields, Max Records Per FlowFile, Personal Access Token, Query Page Size, Query Time Window Lag, Table ID, Web Client Service Provider, success | Tags: airtable, query, database; Stateful; WritesAttributes | nifi-extension-bundles/nifi-airtable-bundle/nifi-airtable-processors/src/main/java/org/apache/nifi/processors/airtable/QueryAirtableTable.java | Query records from an Airtable table. Records are incrementally retrieved based on the last modified time of the records. Records can also be further filtered by setting the 'Custom Filter' property which supports the formulas provided by the Airtable API. This processor is intended to be run on the Primary Node only. |
| `org.apache.nifi.processors.asana.GetAsanaObject` | 1 (required 5) | Asana Client Service, Distributed Cache Service, Object Type, Output Batch Size, Project Name, Section Name, Tag, Team | Tags: asana, source, ingest | nifi-extension-bundles/nifi-asana-bundle/nifi-asana-processors/src/main/java/org/apache/nifi/processors/asana/GetAsanaObject.java | This processor collects data from Asana |
| `org.apache.nifi.processors.attributes.UpdateAttribute` | 5 (required 2) | canonical-value-lookup-cache-size, set state fail, success | Tags: attributes, modification, update, delete, Attribute Expression Language, state; Stateful | nifi-extension-bundles/nifi-update-attribute-bundle/nifi-update-attribute-processor/src/main/java/org/apache/nifi/processors/attributes/UpdateAttribute.java | Updates the Attributes for a FlowFile by using the Attribute Expression Language and/or deletes the attributes based on a regular expression |
| `org.apache.nifi.processors.avro.ExtractAvroMetadata` | 3 (required 2) | Count Items, Fingerprint Algorithm, Metadata Keys, failure, success | Tags: avro, schema, metadata; WritesAttributes | nifi-extension-bundles/nifi-avro-bundle/nifi-avro-processors/src/main/java/org/apache/nifi/processors/avro/ExtractAvroMetadata.java | Extracts metadata from the header of an Avro datafile. |
| `org.apache.nifi.processors.avro.SplitAvro` | 4 (required 4) | Output Size, Output Strategy, Split Strategy, Transfer Metadata, failure, original, split | Tags: avro, split; WritesAttributes | nifi-extension-bundles/nifi-avro-bundle/nifi-avro-processors/src/main/java/org/apache/nifi/processors/avro/SplitAvro.java | Splits a binary encoded Avro datafile into smaller files based on the configured Output Size. The Output Strategy determines if the smaller files will be Avro datafiles, or bare Avro records with metadata in the FlowFile attributes. The output will always be binary encoded. |
| `org.apache.nifi.processors.aws.cloudwatch.PutCloudWatchMetric` | 10 (required 2) | Maximum, Metric Name, Minimum, Namespace, Sample Count, Sum, Timestamp, Unit, Value | Tags: amazon, aws, cloudwatch, metrics, put, publish | nifi-extension-bundles/nifi-aws-bundle/nifi-aws-processors/src/main/java/org/apache/nifi/processors/aws/cloudwatch/PutCloudWatchMetric.java | Publishes metrics to Amazon CloudWatch. Metric can be either a single value, or a StatisticSet comprised of minimum, maximum, sum and sample count. |
| `org.apache.nifi.processors.aws.dynamodb.DeleteDynamoDB` |  |  | Tags: Amazon, DynamoDB, AWS, Delete, Remove; WritesAttributes; ReadsAttributes | nifi-extension-bundles/nifi-aws-bundle/nifi-aws-processors/src/main/java/org/apache/nifi/processors/aws/dynamodb/DeleteDynamoDB.java | Deletes a document from DynamoDB based on hash and range key. The key can be string or number. The request requires all the primary keys for the operation (hash or hash and range key) |
| `org.apache.nifi.processors.aws.dynamodb.GetDynamoDB` | 1 (required 0) | not found | Tags: Amazon, DynamoDB, AWS, Get, Fetch; WritesAttributes; ReadsAttributes | nifi-extension-bundles/nifi-aws-bundle/nifi-aws-processors/src/main/java/org/apache/nifi/processors/aws/dynamodb/GetDynamoDB.java | Retrieves a document from DynamoDB based on hash and range key.  The key can be string or number.For any get request all the primary keys are required (hash or hash and range based on the table keys).A Json Document ('Map') attribute of the DynamoDB item is read into the content of the FlowFile. |
| `org.apache.nifi.processors.aws.dynamodb.PutDynamoDB` |  |  | Tags: Amazon, DynamoDB, AWS, Put, Insert; WritesAttributes; ReadsAttributes | nifi-extension-bundles/nifi-aws-bundle/nifi-aws-processors/src/main/java/org/apache/nifi/processors/aws/dynamodb/PutDynamoDB.java | Puts a document from DynamoDB based on hash and range key.  The table can have either hash and range or hash key alone. Currently the keys supported are string and number and value can be json document. In case of hash and range keys both key are required for the operation. The FlowFile content must be JSON. FlowFile content is mapped to the specified Json Document attribute in the DynamoDB item. |
| `org.apache.nifi.processors.aws.dynamodb.PutDynamoDBRecord` | 6 (required 6) | Partition Key Attribute, Partition Key Field, Partition Key Strategy, Record Reader, Sort Key Field, Sort Key Strategy | Tags: Amazon, DynamoDB, AWS, Put, Insert, Record; WritesAttributes | nifi-extension-bundles/nifi-aws-bundle/nifi-aws-processors/src/main/java/org/apache/nifi/processors/aws/dynamodb/PutDynamoDBRecord.java |  |
| `org.apache.nifi.processors.aws.dynamodb.for` | 10 (required 7) | Batch items for each request (between 1 and 50), Character set of document, Hash Key Name, Hash Key Value, Hash Key Value Type, Json Document attribute, Range Key Name, Range Key Value, Range Key Value Type, Table Name, unprocessed |  | nifi-extension-bundles/nifi-aws-bundle/nifi-aws-abstract-processors/src/main/java/org/apache/nifi/processors/aws/dynamodb/AbstractDynamoDBProcessor.java |  |
| `org.apache.nifi.processors.aws.kinesis.firehose.PutKinesisFirehose` | 3 (required 1) | Amazon Kinesis Firehose Delivery Stream Name, Batch Size, Max message buffer size | Tags: amazon, aws, firehose, kinesis, put, stream; WritesAttributes | nifi-extension-bundles/nifi-aws-bundle/nifi-aws-processors/src/main/java/org/apache/nifi/processors/aws/kinesis/firehose/PutKinesisFirehose.java | Sends the contents to a specified Amazon Kinesis Firehose. In order to send data to firehose, the firehose delivery stream name has to be specified. |
| `org.apache.nifi.processors.aws.kinesis.stream.ConsumeKinesisStream` | 19 (required 13) | Amazon Kinesis Stream Name, Application Name, Checkpoint Interval, DynamoDB Override, Failover Timeout, FlowFile Handling On Schema Difference, Graceful Shutdown Timeout, Initial Stream Position, Output Strategy, Record Reader, Record Writer, Report Metrics to CloudWatch, Retry Count, Retry Wait, Stream Position Timestamp, Timestamp Format, parse.failure | Tags: amazon, aws, kinesis, consume, stream; WritesAttributes | nifi-extension-bundles/nifi-aws-bundle/nifi-aws-processors/src/main/java/org/apache/nifi/processors/aws/kinesis/stream/ConsumeKinesisStream.java | Reads data from the specified AWS Kinesis stream and outputs a FlowFile for every processed Record (raw)  or a FlowFile for a batch of processed records if a Record Reader and Record Writer are configured. At-least-once delivery of all Kinesis Records within the Stream while the processor is running. AWS Kinesis Client Library can take several seconds to initialise before starting to fetch data. Uses DynamoDB for check pointing and CloudWatch (optional) for metrics. Ensure that the credentials provided have access to DynamoDB and CloudWatch (optional) along with Kinesis. |
| `org.apache.nifi.processors.aws.kinesis.stream.PutKinesisStream` | 4 (required 1) | Max Message Buffer Size, Message Batch Size, Stream Name, Stream Partition Key | Tags: amazon, aws, kinesis, put, stream; WritesAttributes | nifi-extension-bundles/nifi-aws-bundle/nifi-aws-processors/src/main/java/org/apache/nifi/processors/aws/kinesis/stream/PutKinesisStream.java | Sends the contents to a specified Amazon Kinesis. In order to send data to Kinesis, the stream name has to be specified. |
| `org.apache.nifi.processors.aws.kinesis.stream.record.KinesisRecordProcessorRaw` |  |  |  | nifi-extension-bundles/nifi-aws-bundle/nifi-aws-processors/src/main/java/org/apache/nifi/processors/aws/kinesis/stream/record/KinesisRecordProcessorRaw.java |  |
| `org.apache.nifi.processors.aws.kinesis.stream.record.KinesisRecordProcessorRecord` |  |  |  | nifi-extension-bundles/nifi-aws-bundle/nifi-aws-processors/src/main/java/org/apache/nifi/processors/aws/kinesis/stream/record/KinesisRecordProcessorRecord.java |  |
| `org.apache.nifi.processors.aws.lambda.PutLambda` | 2 (required 2) | Amazon Lambda Name, Amazon Lambda Qualifier (version) | Tags: amazon, aws, lambda, put; WritesAttributes | nifi-extension-bundles/nifi-aws-bundle/nifi-aws-processors/src/main/java/org/apache/nifi/processors/aws/lambda/PutLambda.java | Sends the contents to a specified Amazon Lambda Function. The AWS credentials used for authentication must have permissions execute the Lambda function (lambda:InvokeFunction).The FlowFile content must be JSON. |
| `org.apache.nifi.processors.aws.ml.polly.GetAwsPollyJobStatus` |  |  | Tags: Amazon, AWS, ML, Machine Learning, Polly; WritesAttributes | nifi-extension-bundles/nifi-aws-bundle/nifi-aws-processors/src/main/java/org/apache/nifi/processors/aws/ml/polly/GetAwsPollyJobStatus.java | Retrieves the current status of an AWS Polly job. |
| `org.apache.nifi.processors.aws.ml.textract.GetAwsTextractJobStatus` | 1 (required 1) | Textract Type | Tags: Amazon, AWS, ML, Machine Learning, Textract | nifi-extension-bundles/nifi-aws-bundle/nifi-aws-processors/src/main/java/org/apache/nifi/processors/aws/ml/textract/GetAwsTextractJobStatus.java | Retrieves the current status of an AWS Textract job. |
| `org.apache.nifi.processors.aws.ml.transcribe.GetAwsTranscribeJobStatus` |  |  | Tags: Amazon, AWS, ML, Machine Learning, Transcribe; WritesAttributes | nifi-extension-bundles/nifi-aws-bundle/nifi-aws-processors/src/main/java/org/apache/nifi/processors/aws/ml/transcribe/GetAwsTranscribeJobStatus.java | Retrieves the current status of an AWS Transcribe job. |
| `org.apache.nifi.processors.aws.ml.translate.GetAwsTranslateJobStatus` |  |  | Tags: Amazon, AWS, ML, Machine Learning, Translate; WritesAttributes | nifi-extension-bundles/nifi-aws-bundle/nifi-aws-processors/src/main/java/org/apache/nifi/processors/aws/ml/translate/GetAwsTranslateJobStatus.java | Retrieves the current status of an AWS Translate job. |
| `org.apache.nifi.processors.aws.s3.AbstractS3Processor` | 17 (required 3) | Bucket, Canned ACL, Custom Signer Class Name, Custom Signer Module Location, Encryption Service, FullControl User List, Object Key, Owner, Read ACL User List, Read Permission User List, Signer Override, Use Chunked Encoding, Use Path Style Access, Version, Write ACL User List, Write Permission User List |  | nifi-extension-bundles/nifi-aws-bundle/nifi-aws-abstract-processors/src/main/java/org/apache/nifi/processors/aws/s3/AbstractS3Processor.java |  |
| `org.apache.nifi.processors.aws.s3.CopyS3Object` | 4 (required 0) | Destination Bucket, Destination Key, Source Bucket, Source Key | Tags: Amazon, S3, AWS, Archive, Copy | nifi-extension-bundles/nifi-aws-bundle/nifi-aws-processors/src/main/java/org/apache/nifi/processors/aws/s3/CopyS3Object.java | Copies a file from one bucket and key to another in AWS S3 |
| `org.apache.nifi.processors.aws.s3.GetS3ObjectMetadata` | 3 (required 1) | Metadata Attribute Include Pattern, Metadata Target, found, not found | Tags: Amazon, S3, AWS, Archive, Exists | nifi-extension-bundles/nifi-aws-bundle/nifi-aws-processors/src/main/java/org/apache/nifi/processors/aws/s3/GetS3ObjectMetadata.java | Check for the existence of an Object in S3 and fetch its Metadata without attempting to download it. This processor can be used as a router for workflows that need to check on an Object in S3 before proceeding with data processing |
| `org.apache.nifi.processors.aws.s3.GetS3ObjectTags` | 3 (required 1) | Tag Attribute Include Pattern, Tags Target, found, not found | Tags: Amazon, S3, AWS, Archive, Exists | nifi-extension-bundles/nifi-aws-bundle/nifi-aws-processors/src/main/java/org/apache/nifi/processors/aws/s3/GetS3ObjectTags.java | Check for the existence of an Object in S3 and fetch its Tags without attempting to download it. This processor can be used as a router for workflows that need to check on an Object in S3 before proceeding with data processing |
| `org.apache.nifi.processors.aws.s3.name` | 14 (required 7) | Cache Control, Content Disposition, Content Type, Expiration Time Rule, Multipart Part Size, Multipart Threshold, Multipart Upload AgeOff Interval, Multipart Upload Max Age Threshold, Object Tags Prefix, Remove Tag Prefix, Server Side Encryption, Storage Class, Temporary Directory Multipart State | Tags: Amazon, S3, AWS, Archive, Put; WritesAttributes | nifi-extension-bundles/nifi-aws-bundle/nifi-aws-processors/src/main/java/org/apache/nifi/processors/aws/s3/PutS3Object.java | Writes the contents of a FlowFile as an S3 Object to an Amazon S3 Bucket. |
| `org.apache.nifi.processors.aws.s3.of` | 4 (required 10) | Delimiter, List Type, Listing Batch Size, Listing Strategy, Maximum Object Age, Minimum Object Age, Prefix, Record Writer, Requester Pays, Use Versions, Write Object Tags, Write User Metadata | Tags: Amazon, S3, AWS, list; Stateful; WritesAttributes | nifi-extension-bundles/nifi-aws-bundle/nifi-aws-processors/src/main/java/org/apache/nifi/processors/aws/s3/ListS3.java | Retrieves a listing of objects from an S3 bucket. For each object that is listed, creates a FlowFile that represents the object so that it can be fetched in conjunction with FetchS3Object. This Processor is designed to run on Primary Node only in a cluster. If the primary node changes, the new Primary Node will pick up where the previous node left off without duplicating all of the data. |
| `org.apache.nifi.processors.aws.sns.PutSNS` | 8 (required 4) | ARN Type, Amazon Resource Name (ARN), Character Set, Deduplication Message ID, E-mail Subject, Message Group ID, Use JSON Structure | Tags: amazon, aws, sns, topic, put, publish, pubsub | nifi-extension-bundles/nifi-aws-bundle/nifi-aws-processors/src/main/java/org/apache/nifi/processors/aws/sns/PutSNS.java | Sends the content of a FlowFile as a notification to the Amazon Simple Notification Service |
| `org.apache.nifi.processors.aws.sqs.DeleteSQS` | 2 (required 2) | Queue URL, Receipt Handle | Tags: Amazon, AWS, SQS, Queue, Delete | nifi-extension-bundles/nifi-aws-bundle/nifi-aws-processors/src/main/java/org/apache/nifi/processors/aws/sqs/DeleteSQS.java | Deletes a message from an Amazon Simple Queuing Service Queue |
| `org.apache.nifi.processors.aws.sqs.GetSQS` | 6 (required 6) | Auto Delete Messages, Batch Size, Character Set, Queue URL, Receive Message Wait Time, Visibility Timeout | Tags: Amazon, AWS, SQS, Queue, Get, Fetch, Poll; WritesAttributes | nifi-extension-bundles/nifi-aws-bundle/nifi-aws-processors/src/main/java/org/apache/nifi/processors/aws/sqs/GetSQS.java | Fetches messages from an Amazon Simple Queuing Service Queue |
| `org.apache.nifi.processors.aws.sqs.PutSQS` | 6 (required 3) | Batch Size, Deduplication Message ID, Delay, Message Group ID, Queue URL | Tags: Amazon, AWS, SQS, Queue, Put, Publish | nifi-extension-bundles/nifi-aws-bundle/nifi-aws-processors/src/main/java/org/apache/nifi/processors/aws/sqs/PutSQS.java | Publishes a message to an Amazon Simple Queuing Service Queue |
| `org.apache.nifi.processors.azure.AbstractAzureBlobProcessor_v12` | 1 (required 1) | Blob Name, failure, success |  | nifi-extension-bundles/nifi-azure-bundle/nifi-azure-processors/src/main/java/org/apache/nifi/processors/azure/AbstractAzureBlobProcessor_v12.java |  |
| `org.apache.nifi.processors.azure.AbstractAzureDataLakeStorageProcessor` |  | failure, success |  | nifi-extension-bundles/nifi-azure-bundle/nifi-azure-processors/src/main/java/org/apache/nifi/processors/azure/AbstractAzureDataLakeStorageProcessor.java |  |
| `org.apache.nifi.processors.azure.cosmos.document.AbstractAzureCosmosDBProcessor` | 4 (required 3) | Cosmos DB Connection Service, Cosmos DB Container ID, Cosmos DB Name, Cosmos DB Partition Key, failure, success |  | nifi-extension-bundles/nifi-azure-bundle/nifi-azure-processors/src/main/java/org/apache/nifi/processors/azure/cosmos/document/AbstractAzureCosmosDBProcessor.java |  |
| `org.apache.nifi.processors.azure.cosmos.document.PutAzureCosmosDBRecord` | 3 (required 1) | Cosmos DB Conflict Handling Strategy, Insert Batch Size, Record Reader | Tags: azure, cosmos, insert, record, put | nifi-extension-bundles/nifi-azure-bundle/nifi-azure-processors/src/main/java/org/apache/nifi/processors/azure/cosmos/document/PutAzureCosmosDBRecord.java | This processor is a record-aware processor for inserting data into Cosmos DB with Core SQL API. It uses a configured record reader and schema to read an incoming record set from the body of a Flowfile and then inserts those records into a configured Cosmos DB Container. |
| `org.apache.nifi.processors.azure.data.explorer.PutAzureDataExplorer` | 7 (required 10) | Data Format, Database Name, Ingest Mapping Name, Ingest Status Polling Interval, Ingest Status Polling Timeout, Ingestion Ignore First Record, Kusto Ingest Service, Partially Succeeded Routing Strategy, Poll for Ingest Status, Streaming Enabled, Table Name, failure, success | Tags: Azure, Kusto, ADX, Explorer, Data | nifi-extension-bundles/nifi-azure-bundle/nifi-azure-processors/src/main/java/org/apache/nifi/processors/azure/data/explorer/PutAzureDataExplorer.java | Acts as an Azure Data Explorer sink which sends FlowFiles to the provided endpoint. Data can be sent through queued ingestion or streaming ingestion to the Azure Data Explorer cluster. |
| `org.apache.nifi.processors.azure.data.explorer.QueryAzureDataExplorer` | 3 (required 3) | Database Name, Kusto Query Service, Query, failure, success | Tags: Azure, Data, Explorer, ADX, Kusto; WritesAttributes | nifi-extension-bundles/nifi-azure-bundle/nifi-azure-processors/src/main/java/org/apache/nifi/processors/azure/data/explorer/QueryAzureDataExplorer.java | Query Azure Data Explorer and stream JSON results to output FlowFiles |
| `org.apache.nifi.processors.azure.eventhub.ConsumeAzureEventHub` | 15 (required 9) | Batch Size, Checkpoint Strategy, Consumer Group, Event Hub Name, Event Hub Namespace, Initial Offset, Message Receive Timeout, Prefetch Count, Record Reader, Record Writer, Shared Access Policy Name, Storage Account Key, Storage Account Name, Storage Container Name, Storage SAS Token, parse.failure, success | Tags: azure, microsoft, cloud, eventhub, events, streaming, streams; Stateful; WritesAttributes | nifi-extension-bundles/nifi-azure-bundle/nifi-azure-processors/src/main/java/org/apache/nifi/processors/azure/eventhub/ConsumeAzureEventHub.java | Receives messages from Microsoft Azure Event Hubs with checkpointing to ensure consistent event processing. Checkpoint tracking avoids consuming a message multiple times and enables reliable resumption of processing in the event of intermittent network failures. Checkpoint tracking requires external storage and provides the preferred approach to consuming messages from Azure Event Hubs. In clustered environment, ConsumeAzureEventHub processor instances form a consumer group and the messages are distributed among the cluster nodes (each message is processed on one cluster node only). |
| `org.apache.nifi.processors.azure.eventhub.GetAzureEventHub` | 7 (required 3) | Consumer Group, Event Hub Name, Event Hub Namespace, Message Enqueue Time, Partition Receiver Fetch Size, Partition Receiver Timeout, Shared Access Policy Name, success | Tags: azure, microsoft, cloud, eventhub, events, streaming, streams; WritesAttributes | nifi-extension-bundles/nifi-azure-bundle/nifi-azure-processors/src/main/java/org/apache/nifi/processors/azure/eventhub/GetAzureEventHub.java | Receives messages from Microsoft Azure Event Hubs without reliable checkpoint tracking. In clustered environment, GetAzureEventHub processor instances work independently and all cluster nodes process all messages (unless running the processor in Primary Only mode). ConsumeAzureEventHub offers the recommended approach to receiving messages from Azure Event Hubs. This processor creates a thread pool for connections to Azure Event Hubs. |
| `org.apache.nifi.processors.azure.eventhub.PutAzureEventHub` | 5 (required 3) | Event Hub Name, Event Hub Namespace, Maximum Batch Size, Partitioning Key Attribute Name, Shared Access Policy Name, failure, success | Tags: microsoft, azure, cloud, eventhub, events, streams, streaming | nifi-extension-bundles/nifi-azure-bundle/nifi-azure-processors/src/main/java/org/apache/nifi/processors/azure/eventhub/PutAzureEventHub.java | Send FlowFile contents to Azure Event Hubs |
| `org.apache.nifi.processors.azure.storage.CopyAzureBlobStorage_v12` | 6 (required 4) | Destination Blob Name, Destination Container Name, Destination Storage Credentials, Source Blob Name, Source Container Name, Source Storage Credentials | Tags: azure, microsoft, cloud, storage, blob; WritesAttributes | nifi-extension-bundles/nifi-azure-bundle/nifi-azure-processors/src/main/java/org/apache/nifi/processors/azure/storage/CopyAzureBlobStorage_v12.java | Copies a blob in Azure Blob Storage from one account/container to another. The processor uses Azure Blob Storage client library v12. |
| `org.apache.nifi.processors.azure.storage.DeleteAzureBlobStorage_v12` | 3 (required 1) | Delete Snapshots Option | Tags: azure, microsoft, cloud, storage, blob | nifi-extension-bundles/nifi-azure-bundle/nifi-azure-processors/src/main/java/org/apache/nifi/processors/azure/storage/DeleteAzureBlobStorage_v12.java | Deletes the specified blob from Azure Blob Storage. The processor uses Azure Blob Storage client library v12. |
| `org.apache.nifi.processors.azure.storage.DeleteAzureDataLakeStorage` | 2 (required 1) | Filesystem Object Type | Tags: azure, microsoft, cloud, storage, adlsgen2, datalake | nifi-extension-bundles/nifi-azure-bundle/nifi-azure-processors/src/main/java/org/apache/nifi/processors/azure/storage/DeleteAzureDataLakeStorage.java | Deletes the provided file from Azure Data Lake Storage |
| `org.apache.nifi.processors.azure.storage.FetchAzureBlobStorage_v12` | 4 (required 0) | Range Length, Range Start | Tags: azure, microsoft, cloud, storage, blob; WritesAttributes | nifi-extension-bundles/nifi-azure-bundle/nifi-azure-processors/src/main/java/org/apache/nifi/processors/azure/storage/FetchAzureBlobStorage_v12.java | Retrieves the specified blob from Azure Blob Storage and writes its content to the content of the FlowFile. The processor uses Azure Blob Storage client library v12. |
| `org.apache.nifi.processors.azure.storage.FetchAzureDataLakeStorage` | 3 (required 0) | Number of Retries, Range Length, Range Start | Tags: azure, microsoft, cloud, storage, adlsgen2, datalake; WritesAttributes | nifi-extension-bundles/nifi-azure-bundle/nifi-azure-processors/src/main/java/org/apache/nifi/processors/azure/storage/FetchAzureDataLakeStorage.java | Fetch the specified file from Azure Data Lake Storage |
| `org.apache.nifi.processors.azure.storage.ListAzureBlobStorage_v12` | 5 (required 0) | Blob Name Prefix | Tags: azure, microsoft, cloud, storage, blob; Stateful; WritesAttributes | nifi-extension-bundles/nifi-azure-bundle/nifi-azure-processors/src/main/java/org/apache/nifi/processors/azure/storage/ListAzureBlobStorage_v12.java | Lists blobs in an Azure Blob Storage container. Listing details are attached to an empty FlowFile for use with FetchAzureBlobStorage. This Processor is designed to run on Primary Node only in a cluster. If the primary node changes, the new Primary Node will pick up where the previous node left off without duplicating all of the data. The processor uses Azure Blob Storage client library v12. |
| `org.apache.nifi.processors.azure.storage.ListAzureDataLakeStorage` | 4 (required 2) | File Filter, Include Temporary Files, Path Filter, Recurse Subdirectories | Tags: azure, microsoft, cloud, storage, adlsgen2, datalake; Stateful; WritesAttributes | nifi-extension-bundles/nifi-azure-bundle/nifi-azure-processors/src/main/java/org/apache/nifi/processors/azure/storage/ListAzureDataLakeStorage.java | Lists directory in an Azure Data Lake Storage Gen 2 filesystem |
| `org.apache.nifi.processors.azure.storage.MoveAzureDataLakeStorage` | 5 (required 5) | Conflict Resolution Strategy, Destination Directory, Destination Filesystem, Source Directory, Source Filesystem | Tags: azure, microsoft, cloud, storage, adlsgen2, datalake; WritesAttributes | nifi-extension-bundles/nifi-azure-bundle/nifi-azure-processors/src/main/java/org/apache/nifi/processors/azure/storage/MoveAzureDataLakeStorage.java | Moves content within an Azure Data Lake Storage Gen 2. After the move, files will be no longer available on source location. |
| `org.apache.nifi.processors.azure.storage.PutAzureBlobStorage_v12` |  |  | Tags: azure, microsoft, cloud, storage, blob; WritesAttributes | nifi-extension-bundles/nifi-azure-bundle/nifi-azure-processors/src/main/java/org/apache/nifi/processors/azure/storage/PutAzureBlobStorage_v12.java | Puts content into a blob on Azure Blob Storage. The processor uses Azure Blob Storage client library v12. |
| `org.apache.nifi.processors.azure.storage.PutAzureDataLakeStorage` | 3 (required 2) | Base Temporary Path, Conflict Resolution Strategy, Writing Strategy | Tags: azure, microsoft, cloud, storage, adlsgen2, datalake; WritesAttributes | nifi-extension-bundles/nifi-azure-bundle/nifi-azure-processors/src/main/java/org/apache/nifi/processors/azure/storage/PutAzureDataLakeStorage.java | Writes the contents of a FlowFile as a file on Azure Data Lake Storage Gen 2 |
| `org.apache.nifi.processors.azure.storage.queue.AbstractAzureQueueStorage_v12` | 4 (required 3) | Credentials Service, Queue Name, Request Timeout, failure, success |  | nifi-extension-bundles/nifi-azure-bundle/nifi-azure-processors/src/main/java/org/apache/nifi/processors/azure/storage/queue/AbstractAzureQueueStorage_v12.java |  |
| `org.apache.nifi.processors.box.AbstractBoxProcessor` | 1 (required 1) | Box Client Service |  | nifi-extension-bundles/nifi-box-bundle/nifi-box-processors/src/main/java/org/apache/nifi/processors/box/AbstractBoxProcessor.java |  |
| `org.apache.nifi.processors.box.ConsumeBoxEnterpriseEvents` | 3 (required 2) | Event Types, Start Event Position, Start Offset, success | Tags: box, storage; Stateful | nifi-extension-bundles/nifi-box-bundle/nifi-box-processors/src/main/java/org/apache/nifi/processors/box/ConsumeBoxEnterpriseEvents.java |  |
| `org.apache.nifi.processors.box.ConsumeBoxEvents` | 1 (required 1) | Queue Capacity, success | Tags: box, storage; Stateful | nifi-extension-bundles/nifi-box-bundle/nifi-box-processors/src/main/java/org/apache/nifi/processors/box/ConsumeBoxEvents.java |  |
| `org.apache.nifi.processors.box.CreateBoxFileMetadataInstance` | 3 (required 3) | File ID, Record Reader, Template Key, failure, file not found, success, template not found | Tags: box, storage, metadata, templates, create; WritesAttributes | nifi-extension-bundles/nifi-box-bundle/nifi-box-processors/src/main/java/org/apache/nifi/processors/box/CreateBoxFileMetadataInstance.java |  |
| `org.apache.nifi.processors.box.CreateBoxMetadataTemplate` | 4 (required 4) | Hidden, Record Reader, Template Key, Template Name, failure, success | Tags: box, storage, metadata, templates, create; WritesAttributes | nifi-extension-bundles/nifi-box-bundle/nifi-box-processors/src/main/java/org/apache/nifi/processors/box/CreateBoxMetadataTemplate.java |  |
| `org.apache.nifi.processors.box.DeleteBoxFileMetadataInstance` | 2 (required 2) | File ID, Template Key, failure, file not found, success, template not found | Tags: box, storage, metadata, templates, delete; WritesAttributes | nifi-extension-bundles/nifi-box-bundle/nifi-box-processors/src/main/java/org/apache/nifi/processors/box/DeleteBoxFileMetadataInstance.java | Deletes a metadata instance from a Box file using the specified template key |
| `org.apache.nifi.processors.box.ExtractStructuredBoxFileMetadata` | 4 (required 4) | Extraction Method, File ID, Record Reader, Template Key, failure, file not found, success, template not found | Tags: box, storage, metadata, ai, extract; WritesAttributes | nifi-extension-bundles/nifi-box-bundle/nifi-box-processors/src/main/java/org/apache/nifi/processors/box/ExtractStructuredBoxFileMetadata.java | Extracts metadata from a Box file using Box AI. The extraction can use either a template or a list of fields. The extracted metadata is written to the FlowFile content as JSON. |
| `org.apache.nifi.processors.box.FetchBoxFile` | 1 (required 1) | File ID, failure, success | Tags: box, storage, fetch; WritesAttributes | nifi-extension-bundles/nifi-box-bundle/nifi-box-processors/src/main/java/org/apache/nifi/processors/box/FetchBoxFile.java | Fetches files from a Box Folder. Designed to be used in tandem with ListBoxFile. |
| `org.apache.nifi.processors.box.FetchBoxFileInfo` | 1 (required 1) | File ID, failure, not.found, success | Tags: box, storage, metadata, fetch; WritesAttributes | nifi-extension-bundles/nifi-box-bundle/nifi-box-processors/src/main/java/org/apache/nifi/processors/box/FetchBoxFileInfo.java | Fetches metadata for files from Box and adds it to the FlowFile's attributes. |
| `org.apache.nifi.processors.box.FetchBoxFileMetadataInstance` | 3 (required 3) | File ID, Template Key, Template Scope, failure, file not found, success, template not found | Tags: box, storage, metadata, instance, template; WritesAttributes | nifi-extension-bundles/nifi-box-bundle/nifi-box-processors/src/main/java/org/apache/nifi/processors/box/FetchBoxFileMetadataInstance.java | Retrieves specific metadata instance associated with a Box file using template key and scope. |
| `org.apache.nifi.processors.box.FetchBoxFileRepresentation` | 1 (required 2) | File ID, Representation Type, failure, file.not.found, representation.not.found, success | Tags: box, cloud, storage, file, representation, content, download; WritesAttributes | nifi-extension-bundles/nifi-box-bundle/nifi-box-processors/src/main/java/org/apache/nifi/processors/box/FetchBoxFileRepresentation.java | Fetches a Box file representation using a representation hint and writes it to the FlowFile content. |
| `org.apache.nifi.processors.box.GetBoxFileCollaborators` | 3 (required 1) | File ID, Roles, Statuses, failure, not.found, success | Tags: box, storage, collaboration, permissions, sharing; WritesAttributes | nifi-extension-bundles/nifi-box-bundle/nifi-box-processors/src/main/java/org/apache/nifi/processors/box/GetBoxFileCollaborators.java | Retrieves all collaborators on a Box file and adds the collaboration information to the FlowFile's attributes. |
| `org.apache.nifi.processors.box.GetBoxGroupMembers` | 1 (required 1) | Group ID, failure, not.found, success | Tags: box, storage, metadata; WritesAttributes; ReadsAttributes | nifi-extension-bundles/nifi-box-bundle/nifi-box-processors/src/main/java/org/apache/nifi/processors/box/GetBoxGroupMembers.java | Retrieves members for a Box Group and writes their details in FlowFile attributes. |
| `org.apache.nifi.processors.box.ListBoxFile` | 7 (required 3) | Folder ID, Minimum File Age, Search Recursively | Tags: box, storage; Stateful; WritesAttributes | nifi-extension-bundles/nifi-box-bundle/nifi-box-processors/src/main/java/org/apache/nifi/processors/box/ListBoxFile.java | Lists files in a Box folder. Each listed file may result in one FlowFile, the metadata being written as FlowFile attributes. Or - in case the 'Record Writer' property is set - the entire result is written as records to a single FlowFile. This Processor is designed to run on Primary Node only in a cluster. If the primary node changes, the new Primary Node will pick up where the previous node left off without duplicating all of the data. |
| `org.apache.nifi.processors.box.ListBoxFileInfo` | 4 (required 4) | Folder ID, Minimum File Age, Record Writer, Search Recursively, failure, not.found, success | Tags: box, storage, fetch, folder, files; WritesAttributes | nifi-extension-bundles/nifi-box-bundle/nifi-box-processors/src/main/java/org/apache/nifi/processors/box/ListBoxFileInfo.java | Fetches file metadata for each file in a Box Folder. Takes a flowFile with a folder ID attribute and outputs flowFiles with records containing all file metadata. |
| `org.apache.nifi.processors.box.ListBoxFileMetadataInstances` | 1 (required 1) | File ID, failure, not found, success | Tags: box, storage, metadata, instances, templates; WritesAttributes | nifi-extension-bundles/nifi-box-bundle/nifi-box-processors/src/main/java/org/apache/nifi/processors/box/ListBoxFileMetadataInstances.java | Retrieves all metadata instances associated with a Box file. |
| `org.apache.nifi.processors.box.ListBoxFileMetadataTemplates` | 1 (required 1) | File ID, failure, not found, success | Tags: box, storage, metadata, templates; WritesAttributes | nifi-extension-bundles/nifi-box-bundle/nifi-box-processors/src/main/java/org/apache/nifi/processors/box/ListBoxFileMetadataTemplates.java | Retrieves all metadata templates associated with a Box file. |
| `org.apache.nifi.processors.box.PutBoxFile` | 6 (required 4) | Chunked Upload Threshold, Conflict Resolution Strategy, Create Subfolder, Filename, Folder ID, Subfolder Name, failure, success | Tags: box, storage, put; WritesAttributes | nifi-extension-bundles/nifi-box-bundle/nifi-box-processors/src/main/java/org/apache/nifi/processors/box/PutBoxFile.java | Puts content to a Box folder. |
| `org.apache.nifi.processors.box.UpdateBoxFileMetadataInstance` | 3 (required 3) | File ID, Record Reader, Template Key, failure, file not found, success, template not found | Tags: box, storage, metadata, templates, update; WritesAttributes | nifi-extension-bundles/nifi-box-bundle/nifi-box-processors/src/main/java/org/apache/nifi/processors/box/UpdateBoxFileMetadataInstance.java |  |
| `org.apache.nifi.processors.cipher.DecryptContentAge` | 3 (required 3) | Private Key Identities, Private Key Identity Resources, Private Key Source, failure, success | Tags: age, age-encryption.org, encryption, ChaCha20-Poly1305, X25519 | nifi-extension-bundles/nifi-cipher-bundle/nifi-cipher-processors/src/main/java/org/apache/nifi/processors/cipher/DecryptContentAge.java |  |
| `org.apache.nifi.processors.cipher.EncryptContentAge` | 4 (required 4) | File Encoding, Public Key Recipient Resources, Public Key Recipients, Public Key Source, failure, success | Tags: age, age-encryption.org, encryption, ChaCha20-Poly1305, X25519 | nifi-extension-bundles/nifi-cipher-bundle/nifi-cipher-processors/src/main/java/org/apache/nifi/processors/cipher/EncryptContentAge.java |  |
| `org.apache.nifi.processors.cipher.VerifyContentMAC` | 5 (required 5) | Message Authentication Code, Message Authentication Code Algorithm, Message Authentication Code Encoding, Secret Key, Secret Key Encoding, failure, success | Tags: Authentication, Signing, MAC, HMAC; WritesAttributes | nifi-extension-bundles/nifi-cipher-bundle/nifi-cipher-processors/src/main/java/org/apache/nifi/processors/cipher/VerifyContentMAC.java | Calculates a Message Authentication Code using the provided Secret Key and compares it with the provided MAC property |
| `org.apache.nifi.processors.compress.ModifyCompression` | 4 (required 4) | Input Compression Strategy, Output Compression Level, Output Compression Strategy, Output Filename Strategy, failure, success | Tags: content, compress, recompress, gzip, bzip2, lzma, xz-lzma2, snappy, snappy-hadoop, snappy framed, lz4-framed, deflate, zstd, brotli | nifi-extension-bundles/nifi-compress-bundle/nifi-compress-processors/src/main/java/org/apache/nifi/processors/compress/ModifyCompression.java | Changes the compression algorithm used to compress the contents of a FlowFile by decompressing the contents of FlowFiles using a user-specified compression algorithm and recompressing the contents using the specified compression format properties. This processor operates in a very memory efficient way so very large objects well beyond the heap size are generally fine to process |
| `org.apache.nifi.processors.document.ExtractDocumentText` |  | extracted, failure, original | Tags: extract, document, text | nifi-extension-bundles/nifi-media-bundle/nifi-media-processors/src/main/java/org/apache/nifi/processors/document/ExtractDocumentText.java | Extract text contents from supported binary document formats using Apache Tika |
| `org.apache.nifi.processors.dropbox.FetchDropbox` | 1 (required 1) | File, failure, success | Tags: dropbox, storage, fetch; WritesAttributes | nifi-extension-bundles/nifi-dropbox-bundle/nifi-dropbox-processors/src/main/java/org/apache/nifi/processors/dropbox/FetchDropbox.java | Fetches files from Dropbox. Designed to be used in tandem with ListDropbox. |
| `org.apache.nifi.processors.dropbox.ListDropbox` | 7 (required 3) | Folder, Minimum File Age, Search Recursively | Tags: dropbox, storage; Stateful; WritesAttributes | nifi-extension-bundles/nifi-dropbox-bundle/nifi-dropbox-processors/src/main/java/org/apache/nifi/processors/dropbox/ListDropbox.java | Retrieves a listing of files from Dropbox (shortcuts are ignored). Each listed file may result in one FlowFile, the metadata being written as FlowFile attributes. When the 'Record Writer' property is set, the entire result is written as records to a single FlowFile. This Processor is designed to run on Primary Node only in a cluster. If the primary node changes, the new Primary Node will pick up where the previous node left off without duplicating all of the data. |
| `org.apache.nifi.processors.dropbox.PutDropbox` | 5 (required 3) | Chunked Upload Size, Chunked Upload Threshold, Conflict Resolution Strategy, Filename, Folder, failure, success | Tags: dropbox, storage, put; WritesAttributes | nifi-extension-bundles/nifi-dropbox-bundle/nifi-dropbox-processors/src/main/java/org/apache/nifi/processors/dropbox/PutDropbox.java | Puts content to a Dropbox folder. |
| `org.apache.nifi.processors.elasticsearch.AbstractByQueryElasticsearch` | 1 (required 0) | failure, success |  | nifi-extension-bundles/nifi-elasticsearch-bundle/nifi-elasticsearch-restapi-processors/src/main/java/org/apache/nifi/processors/elasticsearch/AbstractByQueryElasticsearch.java |  |
| `org.apache.nifi.processors.elasticsearch.AbstractPutElasticsearch` | 6 (required 2) | Batch Size, Index Operation, Output Error Responses, Treat Not Found as Success, error_responses, errors, original, successful |  | nifi-extension-bundles/nifi-elasticsearch-bundle/nifi-elasticsearch-restapi-processors/src/main/java/org/apache/nifi/processors/elasticsearch/AbstractPutElasticsearch.java |  |
| `org.apache.nifi.processors.elasticsearch.GetElasticsearch` | 4 (required 3) | Attribute Name, Destination, Document Id, document, not_found | Tags: json, elasticsearch, elasticsearch7, elasticsearch8, elasticsearch9, put, index, record; WritesAttributes | nifi-extension-bundles/nifi-elasticsearch-bundle/nifi-elasticsearch-restapi-processors/src/main/java/org/apache/nifi/processors/elasticsearch/GetElasticsearch.java | Elasticsearch get processor that uses the official Elastic REST client libraries to fetch a single document from Elasticsearch by _id. Note that the full body of the document will be read into memory before being written to a FlowFile for transfer. |
| `org.apache.nifi.processors.email.ConsumeIMAP` | 2 (required 2) | Mark Messages as Read, Use SSL | Tags: Email, Imap, Get, Ingest, Ingress, Message, Consume | nifi-extension-bundles/nifi-email-bundle/nifi-email-processors/src/main/java/org/apache/nifi/processors/email/ConsumeIMAP.java | Consumes messages from Email Server using IMAP protocol. The raw-bytes of each received email message are written as contents of the FlowFile |
| `org.apache.nifi.processors.email.ConsumePOP3` |  |  | Tags: Email, POP3, Get, Ingest, Ingress, Message, Consume | nifi-extension-bundles/nifi-email-bundle/nifi-email-processors/src/main/java/org/apache/nifi/processors/email/ConsumePOP3.java | Consumes messages from Email Server using POP3 protocol. The raw-bytes of each received email message are written as contents of the FlowFile |
| `org.apache.nifi.processors.email.ExtractEmailAttachments` |  | attachments, failure, original | Tags: split, email; WritesAttributes | nifi-extension-bundles/nifi-email-bundle/nifi-email-processors/src/main/java/org/apache/nifi/processors/email/ExtractEmailAttachments.java | Extract attachments from a mime formatted email file, splitting them into individual flowfiles. |
| `org.apache.nifi.processors.email.ExtractEmailHeaders` | 2 (required 0) | Additional Header List, Email Address Parsing, failure, success | Tags: split, email; WritesAttributes | nifi-extension-bundles/nifi-email-bundle/nifi-email-processors/src/main/java/org/apache/nifi/processors/email/ExtractEmailHeaders.java | Using the flowfile content as source of data, extract header from an RFC compliant  email file adding the relevant attributes to the flowfile. This processor does not perform extensive RFC validation but still requires a bare minimum compliance with RFC 2822 |
| `org.apache.nifi.processors.evtx.ParseEvtx` | 1 (required 1) | Granularity, bad chunk, failure, original, success | Tags: logs, windows, event, evtx, message, file; WritesAttributes; ReadsAttributes | nifi-extension-bundles/nifi-evtx-bundle/nifi-evtx-processors/src/main/java/org/apache/nifi/processors/evtx/ParseEvtx.java | Parses the contents of a Windows Event Log file (evtx) and writes the resulting XML to the FlowFile |
| `org.apache.nifi.processors.excel.SplitExcel` | 2 (required 2) | Password, Protection Type, failure, original, split | Tags: split, text; WritesAttributes | nifi-extension-bundles/nifi-poi-bundle/nifi-poi-services/src/main/java/org/apache/nifi/processors/excel/SplitExcel.java |  |
| `org.apache.nifi.processors.gcp.bigquery.PutBigQuery` | 6 (required 6) | bigquery-api-endpoint | Tags: google, google cloud, bq, bigquery; WritesAttributes | nifi-extension-bundles/nifi-gcp-bundle/nifi-gcp-processors/src/main/java/org/apache/nifi/processors/gcp/bigquery/PutBigQuery.java | Writes the contents of a FlowFile to a Google BigQuery table. The processor is record based so the schema that is used is driven by the RecordReader. Attributes that are not matched to the target schema are skipped. Exactly once delivery semantics are achieved via stream offsets. |
| `org.apache.nifi.processors.gcp.bigquery.for` | 3 (required 3) | failure, success |  | nifi-extension-bundles/nifi-gcp-bundle/nifi-gcp-processors/src/main/java/org/apache/nifi/processors/gcp/bigquery/AbstractBigQueryProcessor.java |  |
| `org.apache.nifi.processors.gcp.drive.FetchGoogleDrive` | 5 (required 5) | Google Doc Export Type, Google Drawing Export Type, Google Presentation Export Type, Google Spreadsheet Export Type, drive-file-id, failure, success | Tags: google, drive, storage, fetch; WritesAttributes | nifi-extension-bundles/nifi-gcp-bundle/nifi-gcp-processors/src/main/java/org/apache/nifi/processors/gcp/drive/FetchGoogleDrive.java | Fetches files from a Google Drive Folder. Designed to be used in tandem with ListGoogleDrive. Please see Additional Details to set up access to Google Drive. |
| `org.apache.nifi.processors.gcp.drive.ListGoogleDrive` | 7 (required 3) | folder-id, min-age, recursive-search | Tags: google, drive, storage; Stateful; WritesAttributes | nifi-extension-bundles/nifi-gcp-bundle/nifi-gcp-processors/src/main/java/org/apache/nifi/processors/gcp/drive/ListGoogleDrive.java | Performs a listing of concrete files (shortcuts are ignored) in a Google Drive folder. If the 'Record Writer' property is set, a single Output FlowFile is created, and each file in the listing is written as a single record to the output file. Otherwise, for each file in the listing, an individual FlowFile is created, the metadata being written as FlowFile attributes. This Processor is designed to run on Primary Node only in a cluster. If the primary node changes, the new Primary Node will pick up where the previous node left off without duplicating all of the data. Please see Additional Details to set up access to Google Drive. |
| `org.apache.nifi.processors.gcp.drive.PutGoogleDrive` | 5 (required 3) | chunked-upload-size, chunked-upload-threshold, conflict-resolution-strategy, failure, file-name, folder-id, success | Tags: google, drive, storage, put; WritesAttributes | nifi-extension-bundles/nifi-gcp-bundle/nifi-gcp-processors/src/main/java/org/apache/nifi/processors/gcp/drive/PutGoogleDrive.java | Writes the contents of a FlowFile as a file in Google Drive. |
| `org.apache.nifi.processors.gcp.pubsub.AbstractGCPubSubProcessor` | 3 (required 4) | api-endpoint, failure, gcp-batch-bytes, gcp-pubsub-publish-batch-delay, gcp-pubsub-publish-batch-size, success |  | nifi-extension-bundles/nifi-gcp-bundle/nifi-gcp-processors/src/main/java/org/apache/nifi/processors/gcp/pubsub/AbstractGCPubSubProcessor.java |  |
| `org.apache.nifi.processors.gcp.pubsub.ConsumeGCPubSub` | 6 (required 6) | Message Demarcator, Output Strategy, Processing Strategy, Record Reader, Record Writer, gcp-pubsub-subscription, parse failure | Tags: google, google-cloud, gcp, message, pubsub, consume; WritesAttributes | nifi-extension-bundles/nifi-gcp-bundle/nifi-gcp-processors/src/main/java/org/apache/nifi/processors/gcp/pubsub/ConsumeGCPubSub.java |  |
| `org.apache.nifi.processors.gcp.pubsub.PublishGCPubSub` | 7 (required 6) | Input Batch Size, Maximum Message Size, Message Derivation Strategy, Record Reader, Record Writer, gcp-pubsub-topic, retry | Tags: google, google-cloud, gcp, message, pubsub, publish; WritesAttributes | nifi-extension-bundles/nifi-gcp-bundle/nifi-gcp-processors/src/main/java/org/apache/nifi/processors/gcp/pubsub/PublishGCPubSub.java | Publishes the content of the incoming flowfile to the configured Google Cloud PubSub topic. The processor supports dynamic properties. If any dynamic properties are present, they will be sent along with the message in the form of 'attributes'. |
| `org.apache.nifi.processors.gcp.storage.DeleteGCSObject` | 1 (required 2) | gcs-bucket, gcs-generation, gcs-key | Tags: google cloud, gcs, google, storage, delete | nifi-extension-bundles/nifi-gcp-bundle/nifi-gcp-processors/src/main/java/org/apache/nifi/processors/gcp/storage/DeleteGCSObject.java | Deletes objects from a Google Cloud Bucket. If attempting to delete a file that does not exist, FlowFile is routed to success. |
| `org.apache.nifi.processors.gcp.storage.FetchGCSObject` | 4 (required 2) | gcs-bucket, gcs-generation, gcs-key, gcs-object-range-length, gcs-object-range-start, gcs-server-side-encryption-key | Tags: google cloud, google, storage, gcs, fetch; WritesAttributes | nifi-extension-bundles/nifi-gcp-bundle/nifi-gcp-processors/src/main/java/org/apache/nifi/processors/gcp/storage/FetchGCSObject.java | Fetches a file from a Google Cloud Bucket. Designed to be used in tandem with ListGCSBucket. |
| `org.apache.nifi.processors.gcp.storage.ListGCSBucket` | 7 (required 5) | gcs-bucket, gcs-prefix, gcs-use-generations, listing-strategy, record-writer | Tags: google cloud, google, storage, gcs, list; Stateful; WritesAttributes | nifi-extension-bundles/nifi-gcp-bundle/nifi-gcp-processors/src/main/java/org/apache/nifi/processors/gcp/storage/ListGCSBucket.java | Retrieves a listing of objects from a GCS bucket. For each object that is listed, creates a FlowFile that represents the object so that it can be fetched in conjunction with FetchGCSObject. This Processor is designed to run on Primary Node only in a cluster. If the primary node changes, the new Primary Node will pick up where the previous node left off without duplicating all of the data. |
| `org.apache.nifi.processors.gcp.storage.PutGCSObject` | 10 (required 3) | gcs-bucket, gcs-content-disposition-type, gcs-content-type, gcs-key, gcs-object-acl, gcs-object-crc32c, gcs-overwrite-object, gcs-server-side-encryption-key, gzip.content.enabled | Tags: google, google cloud, gcs, archive, put; WritesAttributes; ReadsAttributes | nifi-extension-bundles/nifi-gcp-bundle/nifi-gcp-processors/src/main/java/org/apache/nifi/processors/gcp/storage/PutGCSObject.java | Writes the contents of a FlowFile as an object in a Google Cloud Storage. |
| `org.apache.nifi.processors.gcp.storage.for` |  | failure, storage-api-url, success |  | nifi-extension-bundles/nifi-gcp-bundle/nifi-gcp-processors/src/main/java/org/apache/nifi/processors/gcp/storage/AbstractGCSProcessor.java |  |
| `org.apache.nifi.processors.gcp.vision.AbstractGcpVisionProcessor` |  | failure, success |  | nifi-extension-bundles/nifi-gcp-bundle/nifi-gcp-processors/src/main/java/org/apache/nifi/processors/gcp/vision/AbstractGcpVisionProcessor.java |  |
| `org.apache.nifi.processors.gcp.vision.AbstractGetGcpVisionAnnotateOperationStatus` | 1 (required 1) | operationKey, original, running |  | nifi-extension-bundles/nifi-gcp-bundle/nifi-gcp-processors/src/main/java/org/apache/nifi/processors/gcp/vision/AbstractGetGcpVisionAnnotateOperationStatus.java |  |
| `org.apache.nifi.processors.geohash.GeohashRecord` | 9 (required 9) | failure, geohash-format, geohash-level, geohash-record-path, latitude-record-path, longitude-record-path, matched, mode, not matched, original, record-reader, record-writer, routing-strategy, success | Tags: geo, geohash, record; WritesAttributes | nifi-extension-bundles/nifi-geohash-bundle/nifi-geohash-processors/src/main/java/org/apache/nifi/processors/geohash/GeohashRecord.java | A record-based processor that encodes and decodes Geohashes from and to latitude/longitude coordinates. |
| `org.apache.nifi.processors.graph.for` | 3 (required 2) | failure, graph-client-service, graph-query, original, success |  | nifi-extension-bundles/nifi-graph-bundle/nifi-graph-processors/src/main/java/org/apache/nifi/processors/graph/AbstractGraphExecutor.java |  |
| `org.apache.nifi.processors.groovyx.ExecuteGroovyScript` | 9 (required 1) | failure, groovyx-additional-classpath, groovyx-failure-strategy, groovyx-script-body, groovyx-script-file, success | Tags: script, groovy, groovyx; Restricted; Stateful | nifi-extension-bundles/nifi-groovyx-bundle/nifi-groovyx-processors/src/main/java/org/apache/nifi/processors/groovyx/ExecuteGroovyScript.java |  |
| `org.apache.nifi.processors.hadoop.AbstractFetchHDFSRecord` | 2 (required 2) | Filename, Record Writer, failure, retry, success |  | nifi-extension-bundles/nifi-extension-utils/nifi-record-utils/nifi-hadoop-record-utils/src/main/java/org/apache/nifi/processors/hadoop/AbstractFetchHDFSRecord.java |  |
| `org.apache.nifi.processors.hadoop.CreateHadoopSequenceFile` | 1 (required 0) | compression type, failure, success | Tags: hadoop, sequence file, create, sequencefile | nifi-extension-bundles/nifi-hadoop-bundle/nifi-hdfs-processors/src/main/java/org/apache/nifi/processors/hadoop/CreateHadoopSequenceFile.java | Creates Hadoop Sequence Files from incoming flow files |
| `org.apache.nifi.processors.hadoop.DeleteHDFS` | 2 (required 2) | failure, file_or_directory, recursive, success | Tags: hadoop, HCFS, HDFS, delete, remove, filesystem; Restricted; WritesAttributes | nifi-extension-bundles/nifi-hadoop-bundle/nifi-hdfs-processors/src/main/java/org/apache/nifi/processors/hadoop/DeleteHDFS.java | Deletes one or more files or directories from HDFS. The path can be provided as an attribute from an incoming FlowFile, or a statically set path that is periodically removed. If this processor has an incoming connection, itwill ignore running on a periodic basis and instead rely on incoming FlowFiles to trigger a delete. Note that you may use a wildcard character to match multiple files or directories. If there are no incoming connections no flowfiles will be transfered to any output relationships.  If there is an incoming flowfile then provided there are no detected failures it will be transferred to success otherwise it will be sent to false. If knowledge of globbed files deleted is necessary use ListHDFS first to produce a specific list of files to delete.  |
| `org.apache.nifi.processors.hadoop.FetchHDFS` | 1 (required 1) | HDFS Filename, comms.failure, failure, success | Tags: hadoop, hcfs, hdfs, get, ingest, fetch, source; Restricted; WritesAttributes | nifi-extension-bundles/nifi-hadoop-bundle/nifi-hdfs-processors/src/main/java/org/apache/nifi/processors/hadoop/FetchHDFS.java | Retrieves a file from HDFS. The content of the incoming FlowFile is replaced by the content of the file in HDFS. The file in HDFS is left intact without any changes being made to it. |
| `org.apache.nifi.processors.hadoop.GetHDFS` | 10 (required 7) | Batch Size, File Filter Regex, Filter Match Name Only, IO Buffer Size, Ignore Dotted Files, Keep Source File, Maximum File Age, Minimum File Age, Polling Interval, Recurse Subdirectories, success | Tags: hadoop, HCFS, HDFS, get, fetch, ingest, source, filesystem; Restricted; WritesAttributes | nifi-extension-bundles/nifi-hadoop-bundle/nifi-hdfs-processors/src/main/java/org/apache/nifi/processors/hadoop/GetHDFS.java | Fetch files from Hadoop Distributed File System (HDFS) into FlowFiles. This Processor will delete the file from HDFS after fetching it. |
| `org.apache.nifi.processors.hadoop.GetHDFSFileInfo` | 10 (required 6) | failure, gethdfsfileinfo-batch-size, gethdfsfileinfo-destination, gethdfsfileinfo-dir-filter, gethdfsfileinfo-file-exclude-filter, gethdfsfileinfo-file-filter, gethdfsfileinfo-full-path, gethdfsfileinfo-group, gethdfsfileinfo-ignore-dotted-dirs, gethdfsfileinfo-ignore-dotted-files, gethdfsfileinfo-recurse-subdirs, not found, original, success | Tags: hadoop, HCFS, HDFS, get, list, ingest, source, filesystem; WritesAttributes | nifi-extension-bundles/nifi-hadoop-bundle/nifi-hdfs-processors/src/main/java/org/apache/nifi/processors/hadoop/GetHDFSFileInfo.java |  |
| `org.apache.nifi.processors.hadoop.ListHDFS` | 6 (required 3) | File Filter, Recurse Subdirectories, file-filter-mode, maximum-file-age, minimum-file-age, record-writer, success | Tags: hadoop, HCFS, HDFS, get, list, ingest, source, filesystem; Stateful; WritesAttributes | nifi-extension-bundles/nifi-hadoop-bundle/nifi-hdfs-processors/src/main/java/org/apache/nifi/processors/hadoop/ListHDFS.java | Retrieves a listing of files from HDFS. For each file that is listed in HDFS, this processor creates a FlowFile that represents the HDFS file to be fetched in conjunction with FetchHDFS. This Processor is designed to run on Primary Node only in a cluster. If the primary node changes, the new Primary Node will pick up where the previous node left off without duplicating all of the data. Unlike GetHDFS, this Processor does not delete any data from HDFS. |
| `org.apache.nifi.processors.hadoop.MoveHDFS` | 8 (required 5) | Conflict Resolution Strategy, File Filter Regex, HDFS Operation, Ignore Dotted Files, Input Directory or File, Output Directory, Remote Group, Remote Owner, failure, success | Tags: hadoop, HCFS, HDFS, put, move, filesystem, moveHDFS; Restricted; WritesAttributes | nifi-extension-bundles/nifi-hadoop-bundle/nifi-hdfs-processors/src/main/java/org/apache/nifi/processors/hadoop/MoveHDFS.java | Rename existing files or a directory of files (non-recursive) on Hadoop Distributed File System (HDFS). |
| `org.apache.nifi.processors.hadoop.PutHDFS` | 11 (required 3) | Append Mode, Block Size, Conflict Resolution Strategy, IO Buffer Size, Ignore Locality, Permissions umask, Remote Group, Remote Owner, Replication, failure, success, writing-strategy | Tags: hadoop, HCFS, HDFS, put, copy, filesystem; Restricted; WritesAttributes | nifi-extension-bundles/nifi-hadoop-bundle/nifi-hdfs-processors/src/main/java/org/apache/nifi/processors/hadoop/PutHDFS.java | Write FlowFile data to Hadoop Distributed File System (HDFS) |
| `org.apache.nifi.processors.hadoop.for` | 8 (required 3) | Compression Type, Overwrite Files, Permissions Umask, Record Reader, Remote Group, Remote Owner, failure, retry, success |  | nifi-extension-bundles/nifi-extension-utils/nifi-record-utils/nifi-hadoop-record-utils/src/main/java/org/apache/nifi/processors/hadoop/AbstractPutHDFSRecord.java |  |
| `org.apache.nifi.processors.hadoop.inotify.GetHDFSEvents` | 5 (required 5) | Event Types to Filter On, HDFS Path to Watch, IOException Retries During Event Polling, Ignore Hidden Files, Poll Duration, success | Tags: hadoop, events, inotify, notifications, filesystem; Stateful; WritesAttributes | nifi-extension-bundles/nifi-hadoop-bundle/nifi-hdfs-processors/src/main/java/org/apache/nifi/processors/hadoop/inotify/GetHDFSEvents.java | This processor polls the notification events provided by the HdfsAdmin API. Since this uses the HdfsAdmin APIs it is required to run as an HDFS super user. Currently there are six types of events (append, close, create, metadata, rename, and unlink). Please see org.apache.hadoop.hdfs.inotify.Event documentation for full explanations of each event. This processor will poll for new events based on a defined duration. For each event received a new flow file will be created with the expected attributes and the event itself serialized to JSON and written to the flow file's content. For example, if event.type is APPEND then the content of the flow file will contain a JSON file containing the information about the append event. If successful the flow files are sent to the 'success' relationship. Be careful of where the generated flow files are stored. If the flow files are stored in one of processor's watch directories there will be a never ending flow of events. It is also important to be aware that this processor must consume all events. The filtering must happen within the processor. This is because the HDFS admin's event notifications API does not have filtering. |
| `org.apache.nifi.processors.hadoop.that` | 5 (required 2) | Additional Classpath Resources, Compression codec, Directory, Hadoop Configuration Resources, Kerberos User Service |  | nifi-extension-bundles/nifi-extension-utils/nifi-hadoop-utils/src/main/java/org/apache/nifi/processors/hadoop/AbstractHadoopProcessor.java |  |
| `org.apache.nifi.processors.hl7.ExtractHL7Attributes` | 5 (required 5) | Character Encoding, failure, hl7-input-version, parse-segment-fields, skip-validation, success, use-segment-names | Tags: HL7, health level 7, healthcare, extract, attributes | nifi-extension-bundles/nifi-hl7-bundle/nifi-hl7-processors/src/main/java/org/apache/nifi/processors/hl7/ExtractHL7Attributes.java |  |
| `org.apache.nifi.processors.hl7.RouteHL7` | 2 (required 1) | Character Encoding, failure, original | Tags: HL7, healthcare, route, Health Level 7; WritesAttributes | nifi-extension-bundles/nifi-hl7-bundle/nifi-hl7-processors/src/main/java/org/apache/nifi/processors/hl7/RouteHL7.java | Routes incoming HL7 data according to user-defined queries. To add a query, add a new property to the processor. The name of the property will become a new relationship for the processor, and the value is an HL7 Query Language query. If a FlowFile matches the query, a copy of the FlowFile will be routed to the associated relationship. |
| `org.apache.nifi.processors.hubspot.GetHubSpot` | 7 (required 5) | access-token, incremental-delay, incremental-initial-start-time, is-incremental, object-type, result-limit, success, web-client-service-provider | Tags: hubspot; Stateful | nifi-extension-bundles/nifi-hubspot-bundle/nifi-hubspot-processors/src/main/java/org/apache/nifi/processors/hubspot/GetHubSpot.java | Retrieves JSON data from a private HubSpot application. This processor is intended to be run on the Primary Node only. |
| `org.apache.nifi.processors.image.ExtractImageMetadata` | 1 (required 0) | Max Number of Attributes, failure, success | Tags: Exif, Exchangeable, image, file, format, JPG, GIF, PNG, BMP, metadata, IPTC, XMP; WritesAttributes | nifi-extension-bundles/nifi-media-bundle/nifi-media-processors/src/main/java/org/apache/nifi/processors/image/ExtractImageMetadata.java | Extract the image metadata from flowfiles containing images. This processor relies on this metadata extractor library https://github.com/drewnoakes/metadata-extractor. It extracts a long list of metadata types including but not limited to EXIF, IPTC, XMP and Photoshop fields. For the full list visit the library's website.NOTE: The library being used loads the images into memory so extremely large images may cause problems. |
| `org.apache.nifi.processors.image.ResizeImage` | 4 (required 4) | Image Height (in pixels), Image Width (in pixels), Scaling Algorithm, failure, keep-ratio, success | Tags: resize, image, jpg, jpeg, png, bmp, wbmp, gif | nifi-extension-bundles/nifi-media-bundle/nifi-media-processors/src/main/java/org/apache/nifi/processors/image/ResizeImage.java | Resizes an image to user-specified dimensions. This Processor uses the image codecs registered with the environment that NiFi is running in. By default, this includes JPEG, PNG, BMP, WBMP, and GIF images. |
| `org.apache.nifi.processors.jolt.AbstractJoltTransform` | 5 (required 2) | Custom Module Directory, Custom Transformation Class Name, Jolt Specification, Jolt Transform, Transform Cache Size |  | nifi-extension-bundles/nifi-jolt-bundle/nifi-jolt-processors/src/main/java/org/apache/nifi/processors/jolt/AbstractJoltTransform.java |  |
| `org.apache.nifi.processors.jslt.JSLTTransformJSON` | 5 (required 5) | failure, jslt-transform-cache-size, jslt-transform-pretty_print, jslt-transform-result-filter, jslt-transform-transformation, jslt-transform-transformation-strategy, success | Tags: json, jslt, transform | nifi-extension-bundles/nifi-jslt-bundle/nifi-jslt-processors/src/main/java/org/apache/nifi/processors/jslt/JSLTTransformJSON.java | Applies a JSLT transformation to the FlowFile JSON payload. A new FlowFile is created with transformed content and is routed to the 'success' relationship. If the JSLT transform fails, the original FlowFile is routed to the 'failure' relationship. |
| `org.apache.nifi.processors.media.ExtractMediaMetadata` | 4 (required 1) | Max Attribute Length, Max Number of Attributes, Metadata Key Filter, Metadata Key Prefix, failure, success | Tags: media, file, format, metadata, audio, video, image, document, pdf; WritesAttributes | nifi-extension-bundles/nifi-media-bundle/nifi-media-processors/src/main/java/org/apache/nifi/processors/media/ExtractMediaMetadata.java | Extract the content metadata from flowfiles containing audio, video, image, and other file types.  This processor relies on the Apache Tika project for file format detection and parsing.  It extracts a long list of metadata types for media files including audio, video, and print media formats.NOTE: the attribute names and content extracted may vary across upgrades because parsing is performed by the external Tika tools which in turn depend on other projects for metadata extraction.  For the more details and the list of supported file types, visit the library's website at http://tika.apache.org/. |
| `org.apache.nifi.processors.mongodb.AbstractMongoProcessor` | 9 (required 4) | Batch Size, Mongo Collection Name, Mongo Database Name, json-type, mongo-charset, mongo-client-service, mongo-date-format, mongo-query-attribute, results-per-flowfile |  | nifi-extension-bundles/nifi-mongodb-bundle/nifi-mongodb-processors/src/main/java/org/apache/nifi/processors/mongodb/AbstractMongoProcessor.java |  |
| `org.apache.nifi.processors.mongodb.AbstractMongoQueryProcessor` | 6 (required 0) | Batch Size, Limit, Projection, Query, Sort, failure, original, results-per-flowfile, success |  | nifi-extension-bundles/nifi-mongodb-bundle/nifi-mongodb-processors/src/main/java/org/apache/nifi/processors/mongodb/AbstractMongoQueryProcessor.java |  |
| `org.apache.nifi.processors.mongodb.DeleteMongo` | 2 (required 0) | delete-mongo-delete-mode, delete-mongo-fail-on-no-delete, failure, success | Tags: delete, mongo, mongodb | nifi-extension-bundles/nifi-mongodb-bundle/nifi-mongodb-processors/src/main/java/org/apache/nifi/processors/mongodb/DeleteMongo.java |  |
| `org.apache.nifi.processors.mongodb.GetMongo` | 2 (required 1) | get-mongo-send-empty, use-pretty-printing | Tags: mongodb, read, get; WritesAttributes | nifi-extension-bundles/nifi-mongodb-bundle/nifi-mongodb-processors/src/main/java/org/apache/nifi/processors/mongodb/GetMongo.java | Creates FlowFiles from documents in MongoDB loaded by a user-specified query. |
| `org.apache.nifi.processors.mongodb.GetMongoRecord` | 2 (required 2) | get-mongo-record-writer-factory, mongodb-schema-name | Tags: mongo, mongodb, get, fetch, record, json; WritesAttributes | nifi-extension-bundles/nifi-mongodb-bundle/nifi-mongodb-processors/src/main/java/org/apache/nifi/processors/mongodb/GetMongoRecord.java | A record-based version of GetMongo that uses the Record writers to write the MongoDB result set. |
| `org.apache.nifi.processors.mongodb.PutMongo` | 7 (required 4) | Character Set, Mode, Update Method, Update Query Key, Upsert, failure, put-mongo-update-mode, putmongo-update-query, success | Tags: mongodb, insert, update, write, put; WritesAttributes | nifi-extension-bundles/nifi-mongodb-bundle/nifi-mongodb-processors/src/main/java/org/apache/nifi/processors/mongodb/PutMongo.java | Writes the contents of a FlowFile to MongoDB |
| `org.apache.nifi.processors.mongodb.PutMongoBulkOperations` | 2 (required 2) | Character Set, Ordered, failure, success | Tags: mongodb, insert, update, write, put, bulk | nifi-extension-bundles/nifi-mongodb-bundle/nifi-mongodb-processors/src/main/java/org/apache/nifi/processors/mongodb/PutMongoBulkOperations.java | Writes the contents of a FlowFile to MongoDB as bulk-update |
| `org.apache.nifi.processors.mongodb.PutMongoRecord` | 6 (required 4) | bypass-validation, failure, insert_count, ordered, record-reader, success, update-key-fields, update-mode | Tags: mongodb, insert, update, upsert, record, put | nifi-extension-bundles/nifi-mongodb-bundle/nifi-mongodb-processors/src/main/java/org/apache/nifi/processors/mongodb/PutMongoRecord.java |  |
| `org.apache.nifi.processors.mongodb.RunMongoAggregation` | 2 (required 2) | allow-disk-use, failure, mongo-agg-query, original, results | Tags: mongo, aggregation, aggregate | nifi-extension-bundles/nifi-mongodb-bundle/nifi-mongodb-processors/src/main/java/org/apache/nifi/processors/mongodb/RunMongoAggregation.java | A processor that runs an aggregation query whenever a flowfile is received. |
| `org.apache.nifi.processors.mongodb.gridfs.AbstractGridFSProcessor` | 5 (required 2) | failure, gridfs-bucket-name, gridfs-client-service, gridfs-database-name, gridfs-file-name, mongo-query-attribute, success |  | nifi-extension-bundles/nifi-mongodb-bundle/nifi-mongodb-processors/src/main/java/org/apache/nifi/processors/mongodb/gridfs/AbstractGridFSProcessor.java |  |
| `org.apache.nifi.processors.mongodb.gridfs.DeleteGridFS` | 2 (required 0) | delete-gridfs-query, gridfs-file-name | Tags: gridfs, delete, mongodb | nifi-extension-bundles/nifi-mongodb-bundle/nifi-mongodb-processors/src/main/java/org/apache/nifi/processors/mongodb/gridfs/DeleteGridFS.java | Deletes a file from GridFS using a file name or a query. |
| `org.apache.nifi.processors.mongodb.gridfs.FetchGridFS` | 1 (required 0) | gridfs-query, original | Tags: fetch, gridfs, mongo; WritesAttributes | nifi-extension-bundles/nifi-mongodb-bundle/nifi-mongodb-processors/src/main/java/org/apache/nifi/processors/mongodb/gridfs/FetchGridFS.java | Retrieves one or more files from a GridFS bucket by file name or by a user-defined query. |
| `org.apache.nifi.processors.mongodb.gridfs.PutGridFS` | 5 (required 3) | duplicate, gridfs-file-name, putgridfs-chunk-size, putgridfs-enforce-uniqueness, putgridfs-hash-attribute, putgridfs-properties-prefix | Tags: mongo, gridfs, put, file, store | nifi-extension-bundles/nifi-mongodb-bundle/nifi-mongodb-processors/src/main/java/org/apache/nifi/processors/mongodb/gridfs/PutGridFS.java | Writes a file to a GridFS bucket. |
| `org.apache.nifi.processors.mqtt.ConsumeMQTT` | 8 (required 4) | Group ID, Max Queue Size, Message, Quality of Service(QoS), Topic Filter, add-attributes-as-fields, parse.failure | Tags: subscribe, MQTT, IOT, consume, listen; WritesAttributes | nifi-extension-bundles/nifi-mqtt-bundle/nifi-mqtt-processors/src/main/java/org/apache/nifi/processors/mqtt/ConsumeMQTT.java | Subscribes to a topic and receives messages from an MQTT broker |
| `org.apache.nifi.processors.mqtt.PublishMQTT` | 6 (required 3) | Quality of Service(QoS), Retain Message, Topic, failure, success | Tags: publish, MQTT, IOT | nifi-extension-bundles/nifi-mqtt-bundle/nifi-mqtt-processors/src/main/java/org/apache/nifi/processors/mqtt/PublishMQTT.java | Publishes a message to an MQTT topic |
| `org.apache.nifi.processors.mqtt.common.AbstractMQTTProcessor` | 17 (required 6) | Broker URI, Client ID, Connection Timeout (seconds), Keep Alive Interval (seconds), Last Will Message, Last Will QoS Level, Last Will Retain, Last Will Topic, MQTT Specification Version, Password, SSL Context Service, Session Expiry Interval, Session state, Username, message-demarcator, record-reader, record-writer |  | nifi-extension-bundles/nifi-mqtt-bundle/nifi-mqtt-processors/src/main/java/org/apache/nifi/processors/mqtt/common/AbstractMQTTProcessor.java |  |
| `org.apache.nifi.processors.network.ParseNetflowv5` | 1 (required 1) | FIELDS_DESTINATION, failure, original, success | Tags: network, netflow, attributes, datagram, v5, packet, byte; WritesAttributes; ReadsAttributes | nifi-extension-bundles/nifi-network-bundle/nifi-network-processors/src/main/java/org/apache/nifi/processors/network/ParseNetflowv5.java | Parses netflowv5 byte ingest and add to NiFi flowfile as attributes or JSON content. |
| `org.apache.nifi.processors.network.pcap.SplitPCAP` |  | PCAP Max Size, failure, original, split | Tags: PCAP, Splitter, Network, Packet, Capture, Wireshark, TShark, TcpDump, WinDump, sniffers; WritesAttributes | nifi-extension-bundles/nifi-network-bundle/nifi-network-processors/src/main/java/org/apache/nifi/processors/network/pcap/SplitPCAP.java | Splits one pcap file into multiple pcap files based on a maximum size. |
| `org.apache.nifi.processors.opentelemetry.ListenOTLP` | 7 (required 7) | Address, Batch Size, Client Authentication, Port, Queue Capacity, SSL Context Service, Worker Threads, success | Tags: OpenTelemetry, OTel, OTLP, telemetry, metrics, traces, logs; WritesAttributes | nifi-extension-bundles/nifi-opentelemetry-bundle/nifi-opentelemetry-processors/src/main/java/org/apache/nifi/processors/opentelemetry/ListenOTLP.java |  |
| `org.apache.nifi.processors.parquet.CalculateParquetOffsets` | 2 (required 2) | Records Per Split, Zero Content Output, success | Tags: parquet, split, partition, break apart, efficient processing, load balance, cluster; WritesAttributes; ReadsAttributes | nifi-extension-bundles/nifi-parquet-bundle/nifi-parquet-processors/src/main/java/org/apache/nifi/processors/parquet/CalculateParquetOffsets.java |  |
| `org.apache.nifi.processors.parquet.CalculateParquetRowGroupOffsets` | 1 (required 1) | Zero Content Output, success | Tags: parquet, split, partition, break apart, efficient processing, load balance, cluster; WritesAttributes | nifi-extension-bundles/nifi-parquet-bundle/nifi-parquet-processors/src/main/java/org/apache/nifi/processors/parquet/CalculateParquetRowGroupOffsets.java |  |
| `org.apache.nifi.processors.parquet.ConvertAvroToParquet` |  | failure, success | Tags: avro, parquet, convert; WritesAttributes | nifi-extension-bundles/nifi-parquet-bundle/nifi-parquet-processors/src/main/java/org/apache/nifi/processors/parquet/ConvertAvroToParquet.java | Converts Avro records into Parquet file format. The incoming FlowFile should be a valid avro file. If an incoming FlowFile does not contain any records, an empty parquet file is the output. NOTE: Many Avro datatypes (collections, primitives, and unions of primitives, e.g.) can be converted to parquet, but unions of collections and other complex datatypes may not be able to be converted to Parquet. |
| `org.apache.nifi.processors.pgp.DecryptContentPGP` | 3 (required 1) | decryption-strategy, failure, passphrase, private-key-service, success | Tags: PGP, GPG, OpenPGP, Encryption, RFC 4880; WritesAttributes | nifi-extension-bundles/nifi-pgp-bundle/nifi-pgp-processors/src/main/java/org/apache/nifi/processors/pgp/DecryptContentPGP.java | Decrypt contents of OpenPGP messages. Using the Packaged Decryption Strategy preserves OpenPGP encoding to support subsequent signature verification. |
| `org.apache.nifi.processors.pgp.EncryptContentPGP` | 5 (required 2) | failure, file-encoding, passphrase, public-key-search, public-key-service, success, symmetric-key-algorithm | Tags: PGP, GPG, OpenPGP, Encryption, RFC 4880; WritesAttributes | nifi-extension-bundles/nifi-pgp-bundle/nifi-pgp-processors/src/main/java/org/apache/nifi/processors/pgp/EncryptContentPGP.java | Encrypt contents using OpenPGP. The processor reads input and detects OpenPGP messages to avoid unnecessary additional wrapping in Literal Data packets. |
| `org.apache.nifi.processors.pgp.SignContentPGP` | 5 (required 5) | failure, file-encoding, hash-algorithm, private-key-id, private-key-service, signing-strategy, success | Tags: PGP, GPG, OpenPGP, Encryption, Signing, RFC 4880; WritesAttributes | nifi-extension-bundles/nifi-pgp-bundle/nifi-pgp-processors/src/main/java/org/apache/nifi/processors/pgp/SignContentPGP.java | Sign content using OpenPGP Private Keys |
| `org.apache.nifi.processors.pgp.VerifyContentPGP` | 1 (required 1) | failure, public-key-service, success | Tags: PGP, GPG, OpenPGP, Encryption, Signing, RFC 4880; WritesAttributes | nifi-extension-bundles/nifi-pgp-bundle/nifi-pgp-processors/src/main/java/org/apache/nifi/processors/pgp/VerifyContentPGP.java | Verify signatures using OpenPGP Public Keys |
| `org.apache.nifi.processors.salesforce.PutSalesforceObject` | 1 (required 1) | failure, record-reader, success | Tags: salesforce, sobject, put | nifi-extension-bundles/nifi-salesforce-bundle/nifi-salesforce-processors/src/main/java/org/apache/nifi/processors/salesforce/PutSalesforceObject.java | Creates new records for the specified Salesforce sObject. The type of the Salesforce object must be set in the input flowfile's 'objectType' attribute. This processor cannot update existing records. |
| `org.apache.nifi.processors.salesforce.QuerySalesforceObject` | 11 (required 6) | age-delay, age-field, create-zero-record-files, custom-soql-query, custom-where-condition, failure, field-names, include-deleted-records, initial-age-filter, original, query-type, record-writer, sobject-name, success | Tags: salesforce, sobject, soql, query; Stateful; WritesAttributes | nifi-extension-bundles/nifi-salesforce-bundle/nifi-salesforce-processors/src/main/java/org/apache/nifi/processors/salesforce/QuerySalesforceObject.java | Retrieves records from a Salesforce sObject. Users can add arbitrary filter conditions by setting the 'Custom WHERE Condition' property. The processor can also run a custom query, although record processing is not supported in that case. Supports incremental retrieval: users can define a field in the 'Age Field' property that will be used to determine when the record was created. When this property is set the processor will retrieve new records. Incremental loading and record-based processing are only supported in property-based queries. It's also possible to define an initial cutoff value for the age, filtering out all older records even for the first run. In case of 'Property Based Query' this processor should run on the Primary Node only. FlowFile attribute 'record.count' indicates how many records were retrieved and written to the output. The processor can accept an optional input FlowFile and reference the FlowFile attributes in the query. When 'Include Deleted Records' is true, the processor will include deleted records (soft-deletes) in the results by using the 'queryAll' API. The 'IsDeleted' field will be automatically included in the results when querying deleted records. |
| `org.apache.nifi.processors.script.ExecuteScript` | 1 (required 0) |  | Tags: script, execute, groovy, clojure; Restricted; Stateful | nifi-extension-bundles/nifi-scripting-bundle/nifi-scripting-processors/src/main/java/org/apache/nifi/processors/script/ExecuteScript.java | Experimental - Executes a script given the flow file and a process session.  The script is responsible for handling the incoming flow file (transfer to SUCCESS or remove, e.g.) as well as any flow files created by the script. If the handling is incomplete or incorrect, the session will be rolled back. Experimental: Impact of sustained usage not yet verified. |
| `org.apache.nifi.processors.script.ScriptedRecordProcessor` | 3 (required 3) | Record Reader, Record Writer, Script Engine |  | nifi-extension-bundles/nifi-scripting-bundle/nifi-scripting-processors/src/main/java/org/apache/nifi/processors/script/ScriptedRecordProcessor.java |  |
| `org.apache.nifi.processors.script.that` | 1 (required 0) |  | Tags: script, invoke, groovy; Restricted; Stateful | nifi-extension-bundles/nifi-scripting-bundle/nifi-scripting-processors/src/main/java/org/apache/nifi/processors/script/InvokeScriptedProcessor.java | Experimental - Invokes a script engine for a Processor defined in the given script. The script must define a valid class that implements the Processor interface, and it must set a variable 'processor' to an instance of the class. Processor methods such as onTrigger() will be delegated to the scripted Processor instance. Also any Relationships or PropertyDescriptors defined by the scripted processor will be added to the configuration dialog. The scripted processor can implement public void setLogger(ComponentLog logger) to get access to the parent logger, as well as public void onScheduled(ProcessContext context) and public void onStopped(ProcessContext context) methods to be invoked when the parent InvokeScriptedProcessor is scheduled or stopped, respectively.  NOTE: The script will be loaded when the processor is populated with property values, see the Restrictions section for more security implications.  Experimental: Impact of sustained usage not yet verified. |
| `org.apache.nifi.processors.shopify.GetShopify` | 10 (required 7) | access-token, api-version, incremental-delay, incremental-initial-start-time, is-incremental, object-category, result-limit, store-domain, success, web-client-service-provider | Tags: shopify; Stateful | nifi-extension-bundles/nifi-shopify-bundle/nifi-shopify-processors/src/main/java/org/apache/nifi/processors/shopify/GetShopify.java | Retrieves objects from a custom Shopify store. The processor yield time must be set to the account's rate limit accordingly. |
| `org.apache.nifi.processors.slack.ConsumeSlack` | 8 (required 8) | Access Token, Batch Size, Channels, Include Message Blocks, Include Null Fields, Reply Monitor Frequency, Reply Monitor Window, Resolve Usernames, success | Tags: slack, conversation, conversation.history, social media, team, text, unstructured; Stateful; WritesAttributes | nifi-extension-bundles/nifi-slack-bundle/nifi-slack-processors/src/main/java/org/apache/nifi/processors/slack/ConsumeSlack.java | Retrieves messages from one or more configured Slack channels. The messages are written out in JSON format. See Usage / Additional Details for more information about how to configure this Processor and enable it to retrieve messages from Slack. |
| `org.apache.nifi.processors.slack.ListenSlack` | 4 (required 4) | App Token, Bot Token, Event Type to Receive, Resolve User Details, success | Tags: slack, real-time, event, message, command, listen, receive, social media, team, text, unstructured; WritesAttributes | nifi-extension-bundles/nifi-slack-bundle/nifi-slack-processors/src/main/java/org/apache/nifi/processors/slack/ListenSlack.java | Retrieves real-time messages or Slack commands from one or more Slack conversations. The messages are written out in JSON format. Note that this Processor should be used to obtain real-time messages and commands from Slack and does not provide a mechanism for obtaining historical messages. The ConsumeSlack Processor should be used for an initial load of messages from a channel. See Usage / Additional Details for more information about how to configure this Processor and enable it to retrieve messages and commands from Slack. |
| `org.apache.nifi.processors.slack.PublishSlack` | 9 (required 7) | Access Token, Channel, Character Set, Include FlowFile Content as Attachment, Max FlowFile Size, Message Text, Methods Endpoint Url Prefix, Publish Strategy, Thread Timestamp, failure, rate limited, success | Tags: slack, conversation, chat.postMessage, social media, team, text, unstructured, write, upload, send, publish; WritesAttributes | nifi-extension-bundles/nifi-slack-bundle/nifi-slack-processors/src/main/java/org/apache/nifi/processors/slack/PublishSlack.java |  |
| `org.apache.nifi.processors.smb.FetchSmb` | 5 (required 5) | Completion Strategy, Create Destination Directory, Destination Directory, failure, remote-file, smb-client-provider-service, success | Tags: samba, smb, cifs, files, fetch; WritesAttributes | nifi-extension-bundles/nifi-smb-bundle/nifi-smb-processors/src/main/java/org/apache/nifi/processors/smb/FetchSmb.java | Fetches files from a SMB Share. Designed to be used in tandem with ListSmb. |
| `org.apache.nifi.processors.smb.GetSmbFile` | 14 (required 8) | Batch Size, Directory, Domain, File Filter, Hostname, Ignore Hidden Files, Keep Source File, Password, Path Filter, Polling Interval, Recurse Subdirectories, Share, Share Access Strategy, Username, success | Tags: samba, smb, cifs, files, get; WritesAttributes | nifi-extension-bundles/nifi-smb-bundle/nifi-smb-processors/src/main/java/org/apache/nifi/processors/smb/GetSmbFile.java | Reads file from a samba network location to FlowFiles. Use this processor instead of a cifs mounts if share access control is important. Configure the Hostname, Share and Directory accordingly: \\\\[Hostname]\\[Share]\\[path\\to\\Directory] |
| `org.apache.nifi.processors.smb.ListSmb` | 7 (required 4) | directory, file-filter, file-name-suffix-filter, initial-listing-strategy, initial-listing-timestamp, max-file-age, max-file-size, min-file-age, min-file-size, path-filter, smb-client-provider-service | Tags: samba, smb, cifs, files, list; Stateful; WritesAttributes | nifi-extension-bundles/nifi-smb-bundle/nifi-smb-processors/src/main/java/org/apache/nifi/processors/smb/ListSmb.java | Lists concrete files shared via SMB protocol. Each listed file may result in one FlowFile, the metadata being written as FlowFile attributes. Or - in case the 'Record Writer' property is set - the entire result is written as records to a single FlowFile. This Processor is designed to run on Primary Node only in a cluster. If the primary node changes, the new Primary Node will pick up where the previous node left off without duplicating all of the data. |
| `org.apache.nifi.processors.smb.PutSmbFile` | 11 (required 6) | Batch Size, Conflict Resolution Strategy, Create Missing Directories, Directory, Domain, Hostname, Password, Share, Share Access Strategy, Temporary Suffix, Username, failure, success | Tags: samba, smb, cifs, files, put; ReadsAttributes | nifi-extension-bundles/nifi-smb-bundle/nifi-smb-processors/src/main/java/org/apache/nifi/processors/smb/PutSmbFile.java | Writes the contents of a FlowFile to a samba network location. Use this processor instead of a cifs mounts if share access control is important.Configure the Hostname, Share and Directory accordingly: \\\\[Hostname]\\[Share]\\[path\\to\\Directory] |
| `org.apache.nifi.processors.snowflake.GetSnowflakeIngestStatus` | 1 (required 1) | failure, ingest-manager-provider, retry, success | Tags: snowflake, snowpipe, ingest, history; ReadsAttributes | nifi-extension-bundles/nifi-snowflake-bundle/nifi-snowflake-processors/src/main/java/org/apache/nifi/processors/snowflake/GetSnowflakeIngestStatus.java | Waits until a file in a Snowflake stage is ingested. The stage must be created in the Snowflake account beforehand. This processor is usually connected to an upstream StartSnowflakeIngest processor to make sure that the file is ingested. |
| `org.apache.nifi.processors.snowflake.PutSnowflakeInternalStage` | 6 (required 4) | failure, internal-stage, internal-stage-type, snowflake-connection-provider, success, table | Tags: snowflake, jdbc, database, connection, snowpipe; WritesAttributes | nifi-extension-bundles/nifi-snowflake-bundle/nifi-snowflake-processors/src/main/java/org/apache/nifi/processors/snowflake/PutSnowflakeInternalStage.java | Puts files into a Snowflake internal stage. The internal stage must be created in the Snowflake account beforehand. This processor can be connected to a StartSnowflakeIngest processor to ingest the file in the internal stage |
| `org.apache.nifi.processors.snowflake.StartSnowflakeIngest` | 1 (required 1) | failure, ingest-manager-provider, success | Tags: snowflake, snowpipe, ingest; ReadsAttributes | nifi-extension-bundles/nifi-snowflake-bundle/nifi-snowflake-processors/src/main/java/org/apache/nifi/processors/snowflake/StartSnowflakeIngest.java | Ingests files from a Snowflake internal or external stage into a Snowflake table. The stage must be created in the Snowflake account beforehand. The result of the ingestion is not available immediately, so this processor can be connected to an GetSnowflakeIngestStatus processor to wait for the results |
| `org.apache.nifi.processors.splunk.GetSplunk` | 19 (required 9) | API Version, Application, Connection Timeout, Earliest Time, Hostname, Latest Time, Output Mode, Owner, Password, Port, Query, Read Timeout, SSL Context Service, Scheme, Security Protocol, Time Field Strategy, Time Range Strategy, Time Zone, Token, Username, success | Tags: get, splunk, logs; Stateful; WritesAttributes | nifi-extension-bundles/nifi-splunk-bundle/nifi-splunk-processors/src/main/java/org/apache/nifi/processors/splunk/GetSplunk.java | Retrieves data from Splunk Enterprise. |
| `org.apache.nifi.processors.splunk.PutSplunk` |  |  | Tags: splunk, logs, tcp, udp | nifi-extension-bundles/nifi-splunk-bundle/nifi-splunk-processors/src/main/java/org/apache/nifi/processors/splunk/PutSplunk.java | Sends logs to Splunk Enterprise over TCP, TCP + TLS/SSL, or UDP. If a Message Delimiter is provided, then this processor will read messages from the incoming FlowFile based on the delimiter, and send each message to Splunk. If a Message Delimiter is not provided then the content of the FlowFile will be sent directly to Splunk as if it were a single message. |
| `org.apache.nifi.processors.splunk.SplunkAPICall` | 8 (required 4) | Hostname, Owner, Password, Port, Scheme, Security Protocol, Token, Username, request-channel |  | nifi-extension-bundles/nifi-splunk-bundle/nifi-splunk-processors/src/main/java/org/apache/nifi/processors/splunk/SplunkAPICall.java |  |
| `org.apache.nifi.processors.standard.AbstractExecuteSQL` | 10 (required 7) | Content Output Strategy, Database Connection Pooling Service, Max Wait Time, SQL Query, esql-auto-commit, esql-fetch-size, esql-max-rows, esql-output-batch-size, failure, sql-post-query, sql-pre-query, success |  | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/AbstractExecuteSQL.java |  |
| `org.apache.nifi.processors.standard.AbstractJsonPathProcessor` | 2 (required 2) | Max String Length, Null Value Representation |  | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/AbstractJsonPathProcessor.java |  |
| `org.apache.nifi.processors.standard.AbstractQueryDatabaseTable` | 8 (required 5) | initial-load-strategy, qdbt-max-frags, qdbt-max-rows, qdbt-output-batch-size, transaction-isolation-level |  | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/AbstractQueryDatabaseTable.java |  |
| `org.apache.nifi.processors.standard.AbstractRecordProcessor` | 3 (required 3) | Include Zero Record FlowFiles, Record Reader, Record Writer, failure, success |  | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/AbstractRecordProcessor.java |  |
| `org.apache.nifi.processors.standard.AttributesToCSV` | 6 (required 4) | attribute-list, attributes-regex, destination, failure, include-core-attributes, include-schema, null-value, success | Tags: csv, attributes, flowfile; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/AttributesToCSV.java | Generates a CSV representation of the input FlowFile Attributes. The resulting CSV can be written to either a newly generated attribute named 'CSVAttributes' or written to the FlowFile as content.  If the attribute value contains a comma, newline or double quote, then the attribute value will be escaped with double quotes.  Any double quote characters in the attribute value are escaped with another double quote. |
| `org.apache.nifi.processors.standard.AttributesToJSON` | 7 (required 5) | Attributes List, Destination, Include Core Attributes, JSON Handling Strategy, Pretty Print, attributes-to-json-regex, failure, success | Tags: json, attributes, flowfile | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/AttributesToJSON.java | Generates a JSON representation of the input FlowFile Attributes. The resulting JSON can be written to either a new Attribute 'JSONAttributes' or written to the FlowFile as content. Attributes  which contain nested JSON objects can either be handled as JSON or as escaped JSON depending on the strategy chosen. |
| `org.apache.nifi.processors.standard.CalculateRecordStats` | 3 (required 2) | failure, record-stats-limit, record-stats-reader, success | Tags: record, stats, metrics; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/CalculateRecordStats.java | Counts the number of Records in a record set, optionally counting the number of elements per category, where the categories are defined by user-defined properties. |
| `org.apache.nifi.processors.standard.CompressContent` | 4 (required 4) | Compression Format, Compression Level, Mode, Update Filename, failure, success | Tags: content, compress, decompress, gzip, bzip2, lzma, xz-lzma2, snappy, snappy-hadoop, snappy framed, lz4-framed, deflate, zstd, brotli | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/CompressContent.java | Compresses or decompresses the contents of FlowFiles using a user-specified compression algorithm and updates the mime.type attribute as appropriate. A common idiom is to precede CompressContent with IdentifyMimeType and configure Mode='decompress' AND Compression Format='use mime.type attribute'. When used in this manner, the MIME type is automatically detected and the data is decompressed, if necessary. If decompression is unnecessary, the data is passed through to the 'success' relationship. This processor operates in a very memory efficient way so very large objects well beyond the heap size are generally fine to process. |
| `org.apache.nifi.processors.standard.ControlRate` | 8 (required 3) | Grouping Attribute, Maximum Data Rate, Maximum FlowFile Rate, Maximum Rate, Rate Control Criteria, Rate Controlled Attribute, Rate Exceeded Strategy, Time Duration, failure, rate exceeded, success | Tags: rate control, throttle, rate, throughput | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/ControlRate.java | Controls the rate at which data is transferred to follow-on processors. If you configure a very small Time Duration, then the accuracy of the throttle gets worse. You can improve this accuracy by decreasing the Yield Duration, at the expense of more Tasks given to the processor. |
| `org.apache.nifi.processors.standard.ConvertCharacterSet` | 2 (required 2) | Input Character Set, Output Character Set, success | Tags: text, convert, characterset, character set | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/ConvertCharacterSet.java | Converts a FlowFile's content from one character set to another |
| `org.apache.nifi.processors.standard.ConvertRecord` |  |  | Tags: convert, record, generic, schema, json, csv, avro, log, logs, freeform, text; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/ConvertRecord.java |  |
| `org.apache.nifi.processors.standard.CountText` | 7 (required 7) | ajust-immediately, character-encoding, failure, split-words-on-symbols, success, text-character-count, text-line-count, text-line-nonempty-count, text-word-count | Tags: count, text, line, word, character; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/CountText.java | Counts various metrics on incoming text. The requested results will be recorded as attributes. The resulting flowfile will not have its content modified. |
| `org.apache.nifi.processors.standard.CryptographicHashContent` | 2 (required 2) | fail_when_empty, failure, hash_algorithm, success | Tags: content, hash, sha, blake2, md5, cryptography | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/CryptographicHashContent.java | Calculates a cryptographic hash value for the flowfile content using the given algorithm and writes it to an output attribute. Please refer to https://csrc.nist.gov/Projects/Hash-Functions/NIST-Policy-on-Hash-Functions for help to decide which algorithm to use. |
| `org.apache.nifi.processors.standard.DebugFlow` | 22 (required 22) | @OnScheduled Pause Time, @OnStopped Pause Time, @OnUnscheduled Pause Time, Content Size, CustomValidate Pause Time, Fail When @OnScheduled called, Fail When @OnStopped called, Fail When @OnUnscheduled called, FlowFile Exception Class, FlowFile Exception Iterations, FlowFile Failure Iterations, FlowFile Rollback Iterations, FlowFile Rollback Penalty Iterations, FlowFile Rollback Yield Iterations, FlowFile Success Iterations, Ignore Interrupts When Paused, No FlowFile Exception Class, No FlowFile Exception Iterations, No FlowFile Skip Iterations, No FlowFile Yield Iterations, OnTrigger Pause Time, Write Iterations, failure, success | Tags: test, debug, processor, utility, flow, FlowFile | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/DebugFlow.java | The DebugFlow processor aids testing and debugging the FlowFile framework by allowing various responses to be explicitly triggered in response to the receipt of a FlowFile or a timer event without a FlowFile if using timer or cron based scheduling.  It can force responses needed to exercise or test various failure modes that can occur when a processor runs. |
| `org.apache.nifi.processors.standard.DeduplicateRecord` | 12 (required 8) | bloom-filter-certainty, cache-identifier, deduplication-strategy, distributed-map-cache, duplicate, failure, filter-capacity-hint, filter-type, include-zero-record-flowfiles, non-duplicate, original, put-cache-identifier, record-hashing-algorithm, record-reader, record-writer | Tags: text, record, update, change, replace, modify, distinct, unique, filter, hash, dupe, duplicate, dedupe | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/DeduplicateRecord.java | This processor de-duplicates individual records within a record set. It can operate on a per-file basis using an in-memory hashset or bloom filter. When configured with a distributed map cache, it de-duplicates records across multiple files. |
| `org.apache.nifi.processors.standard.DeleteFile` | 2 (required 2) | Directory Path, Filename, failure, not found, success | Tags: file, remove, delete, local, files, filesystem; Restricted | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/DeleteFile.java | Deletes a file from the filesystem. |
| `org.apache.nifi.processors.standard.DeleteSFTP` | 2 (required 2) | Directory Path, Filename, failure, not found, success | Tags: remote, remove, delete, sftp | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/DeleteSFTP.java | Deletes a file residing on an SFTP server. |
| `org.apache.nifi.processors.standard.DetectDuplicate` | 5 (required 3) | Age Off Duration, Cache Entry Identifier, Cache The Entry Identifier, Distributed Cache Service, FlowFile Description, duplicate, failure, non-duplicate | Tags: hash, dupe, duplicate, dedupe | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/DetectDuplicate.java |  |
| `org.apache.nifi.processors.standard.DistributeLoad` | 5 (required 2) | Distribution Strategy, Number of Relationships | Tags: distribute, load balance, route, round robin, weighted; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/DistributeLoad.java | Distributes FlowFiles to downstream processors based on a Distribution Strategy. If using the Round Robin strategy, the default is to assign each destination a weighting of 1 (evenly distributed). However, optional properties can be added to the change this; adding a property with the name '5' and value '10' means that the relationship with name '5' will be receive 10 FlowFiles in each iteration instead of 1. |
| `org.apache.nifi.processors.standard.DuplicateFlowFile` | 1 (required 1) | Number of Copies, success | Tags: test, load, duplicate; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/DuplicateFlowFile.java | Intended for load testing, this processor will create the configured number of copies of each incoming FlowFile. The original FlowFile as well as all generated copies are sent to the 'success' relationship. In addition, each FlowFile gets an attribute 'copy.index' set to the copy number, where the original FlowFile gets a value of zero, and all copies receive incremented integer values. |
| `org.apache.nifi.processors.standard.EncodeContent` | 4 (required 4) | Encoded Line Length, Encoding, Line Output Mode, Mode, failure, success | Tags: encode, decode, base64, base32, hex | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/EncodeContent.java | Encode or decode the contents of a FlowFile using Base64, Base32, or hex encoding schemes |
| `org.apache.nifi.processors.standard.EnforceOrder` | 7 (required 6) | batch-count, failure, group-id, inactive-timeout, initial-order, maximum-order, order-attribute, overtook, skipped, success, wait, wait-timeout | Tags: sort, order; Stateful; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/EnforceOrder.java | Enforces expected ordering of FlowFiles that belong to the same data group within a single node.  Although PriorityAttributePrioritizer can be used on a connection to ensure that flow files going through that connection are in priority order, depending on error-handling, branching, and other flow designs, it is possible for FlowFiles to get out-of-order. EnforceOrder can be used to enforce original ordering for those FlowFiles. [IMPORTANT] In order to take effect of EnforceOrder, FirstInFirstOutPrioritizer should be used at EVERY downstream relationship UNTIL the order of FlowFiles physically get FIXED by operation such as MergeContent or being stored to the final destination. |
| `org.apache.nifi.processors.standard.EvaluateJsonPath` | 4 (required 3) | Destination, Path Not Found Behavior, Return Type, failure, matched, unmatched | Tags: JSON, evaluate, JsonPath | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/EvaluateJsonPath.java | Evaluates one or more JsonPath expressions against the content of a FlowFile. The results of those expressions are assigned to FlowFile Attributes or are written to the content of the FlowFile itself, depending on configuration of the Processor. JsonPaths are entered by adding user-defined properties; the name of the property maps to the Attribute Name into which the result will be placed (if the Destination is flowfile-attribute; otherwise, the property name is ignored). The value of the property must be a valid JsonPath expression. A Return Type of 'auto-detect' will make a determination based off the configured destination. When 'Destination' is set to 'flowfile-attribute,' a return type of 'scalar' will be used. When 'Destination' is set to 'flowfile-content,' a return type of 'JSON' will be used.If the JsonPath evaluates to a JSON array or JSON object and the Return Type is set to 'scalar' the FlowFile will be unmodified and will be routed to failure. A Return Type of JSON can return scalar values if the provided JsonPath evaluates to the specified value and will be routed as a match.If Destination is 'flowfile-content' and the JsonPath does not evaluate to a defined path, the FlowFile will be routed to 'unmatched' without having its contents modified. If Destination is 'flowfile-attribute' and the expression matches nothing, attributes will be created with empty strings as the value unless 'Path Not Found Behaviour' is set to 'skip', and the FlowFile will always be routed to 'matched.' |
| `org.apache.nifi.processors.standard.EvaluateXPath` | 4 (required 3) | Destination, Return Type, Validate DTD, failure, matched, unmatched | Tags: XML, evaluate, XPath | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/EvaluateXPath.java | Evaluates one or more XPaths against the content of a FlowFile. The results of those XPaths are assigned to FlowFile Attributes or are written to the content of the FlowFile itself, depending on configuration of the Processor. XPaths are entered by adding user-defined properties; the name of the property maps to the Attribute Name into which the result will be placed (if the Destination is flowfile-attribute; otherwise, the property name is ignored). The value of the property must be a valid XPath expression. If the XPath evaluates to more than one node and the Return Type is set to 'nodeset' (either directly, or via 'auto-detect' with a Destination of 'flowfile-content'), the FlowFile will be unmodified and will be routed to failure. If the XPath does not evaluate to a Node, the FlowFile will be routed to 'unmatched' without having its contents modified. If Destination is flowfile-attribute and the expression matches nothing, attributes will be created with empty strings as the value, and the FlowFile will always be routed to 'matched' |
| `org.apache.nifi.processors.standard.EvaluateXQuery` | 6 (required 5) | Destination, Output: Indent, Output: Method, Output: Omit XML Declaration, Validate DTD, failure, matched, unmatched | Tags: XML, evaluate, XPath, XQuery | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/EvaluateXQuery.java |  |
| `org.apache.nifi.processors.standard.ExecuteProcess` | 8 (required 2) | Argument Delimiter, Batch Duration, Command, Command Arguments, Output MIME type, Redirect Error Stream, Working Directory, success | Tags: command, process, source, external, invoke, script; Restricted; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/ExecuteProcess.java | Runs an operating system command specified by the user and writes the output of that command to a FlowFile. If the command is expected to be long-running, the Processor can output the partial data on a specified interval. When this option is used, the output is expected to be in textual format, as it typically does not make sense to split binary data on arbitrary time-based intervals. |
| `org.apache.nifi.processors.standard.ExecuteStreamCommand` | 11 (required 2) | Argument Delimiter, Command Arguments, Command Path, Ignore STDIN, Max Attribute Length, Output Destination Attribute, Output MIME Type, Working Directory, argumentsStrategy, nonzero status, original, output stream | Tags: command execution, command, stream, execute; Restricted; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/ExecuteStreamCommand.java | The ExecuteStreamCommand processor provides a flexible way to integrate external commands and scripts into NiFi data flows. ExecuteStreamCommand can pass the incoming FlowFile's content to the command that it executes similarly how piping works. |
| `org.apache.nifi.processors.standard.ExtractGrok` | 7 (required 6) | Character Set, Destination, Grok Expression, Grok Pattern file, Keep Empty Captures, Maximum Buffer Size, Named captures only, matched, unmatched | Tags: grok, log, text, parse, delimit, extract; Restricted; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/ExtractGrok.java | Evaluates one or more Grok Expressions against the content of a FlowFile, adding the results as attributes or replacing the content of the FlowFile with a JSON notation of the matched content |
| `org.apache.nifi.processors.standard.ExtractRecordSchema` | 2 (required 2) | cache-size, failure, record-reader, success | Tags: record, generic, schema, json, csv, avro, freeform, text, xml; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/ExtractRecordSchema.java | Extracts the record schema from the FlowFile using the supplied Record Reader and writes it to the `avro.schema` attribute. |
| `org.apache.nifi.processors.standard.ExtractText` | 16 (required 13) | Character Set, Enable Canonical Equivalence, Enable Case-insensitive Matching, Enable DOTALL Mode, Enable Literal Parsing of the Pattern, Enable Multiline Mode, Enable Unicode Predefined Character Classes, Enable Unicode-aware Case Folding, Enable Unix Lines Mode, Enable named group support, Enable repeating capture group, Include Capture Group 0, Maximum Buffer Size, Maximum Capture Group Length, Permit Whitespace and Comments in Pattern, matched, unmatched | Tags: evaluate, extract, Text, Regular Expression, regex | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/ExtractText.java |  |
| `org.apache.nifi.processors.standard.FetchDistributedMapCache` | 5 (required 2) | Cache Entry Identifier, Character Set, Distributed Cache Service, Max Length To Put In Attribute, Put Cache Value In Attribute, failure, not-found, success | Tags: map, cache, fetch, distributed | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/FetchDistributedMapCache.java | Computes cache key(s) from FlowFile attributes, for each incoming FlowFile, and fetches the value(s) from the Distributed Map Cache associated with each key. If configured without a destination attribute, the incoming FlowFile's content is replaced with the binary data received by the Distributed Map Cache. If there is no value stored under that key then the flow file will be routed to 'not-found'. Note that the processor will always attempt to read the entire cached value into memory before placing it in it's destination. This could be potentially problematic if the cached value is very large. |
| `org.apache.nifi.processors.standard.FetchFile` | 6 (required 5) | Completion Strategy, File to Fetch, Log level when file not found, Log level when permission denied, Move Conflict Strategy, Move Destination Directory, failure, not.found, permission.denied, success | Tags: local, files, filesystem, ingest, ingress, get, source, input, fetch; Restricted | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/FetchFile.java | Reads the contents of a file from disk and streams it into the contents of an incoming FlowFile. Once this is done, the file is optionally moved elsewhere or deleted to help keep the file system organized. |
| `org.apache.nifi.processors.standard.FilterAttribute` | 4 (required 4) | Attribute Matching Strategy, Filter Mode, Filtered Attributes, Filtered Attributes Pattern, success | Tags: attributes, modification, filter, retain, remove, delete, regex, regular expression, Attribute Expression Language | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/FilterAttribute.java | Filters the attributes of a FlowFile by retaining specified attributes and removing the rest or by removing specified attributes and retaining the rest. |
| `org.apache.nifi.processors.standard.FlattenJson` | 6 (required 5) | failure, flatten-json-character-set, flatten-json-pretty-print-json, flatten-json-return-type, flatten-json-separator, flatten-mode, ignore-reserved-characters, success | Tags: json, flatten, unflatten | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/FlattenJson.java |  |
| `org.apache.nifi.processors.standard.ForkEnrichment` |  | enrichment, original | Tags: fork, join, enrich, record; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/ForkEnrichment.java | Used in conjunction with the JoinEnrichment processor, this processor is responsible for adding the attributes that are necessary for the JoinEnrichment processor to perform its function. Each incoming FlowFile will be cloned. The original FlowFile will have appropriate attributes added and then be transferred to the 'original' relationship. The clone will have appropriate attributes added and then be routed to the 'enrichment' relationship. See the documentation for the JoinEnrichment processor (and especially its Additional Details) for more information on how these Processors work together and how to perform enrichment tasks in NiFi by using these Processors. |
| `org.apache.nifi.processors.standard.ForkRecord` | 5 (required 4) | failure, fork, fork-mode, include-parent-fields, original, record-reader, record-writer | Tags: fork, record, content, array, stream, event; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/ForkRecord.java | This processor allows the user to fork a record into multiple records. The user must specify at least one Record Path, as a dynamic property, pointing to a field of type ARRAY containing RECORD objects. The processor accepts two modes: 'split' and 'extract'. In both modes, there is one record generated per element contained in the designated array. In the 'split' mode, each generated record will preserve the same schema as given in the input but the array will contain only one element. In the 'extract' mode, the element of the array must be of record type and will be the generated record. Additionally, in the 'extract' mode, it is possible to specify if each generated record should contain all the fields of the parent records from the root level to the extracted record. This assumes that the fields to add in the record are defined in the schema of the Record Writer controller service. See examples in the additional details documentation of this processor. |
| `org.apache.nifi.processors.standard.GenerateFlowFile` | 8 (required 5) | Batch Size, Data Format, File Size, Unique FlowFiles, character-set, generate-ff-custom-text, mime-type, success | Tags: test, random, generate, load; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/GenerateFlowFile.java | This processor creates FlowFiles with random data or custom content. GenerateFlowFile is useful for load testing, configuration, and simulation. Also see DuplicateFlowFile for additional load testing. |
| `org.apache.nifi.processors.standard.GenerateRecord` | 6 (required 4) | null-percentage, nullable-fields, number-of-records, record-writer, schema-text, success | Tags: test, random, generate, fake; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/GenerateRecord.java | This processor creates FlowFiles with records having random value for the specified fields. GenerateRecord is useful for testing, configuration, and simulation. It uses either user-defined properties to define a record schema or a provided schema and generates the specified number of records using random data for the fields in the schema. |
| `org.apache.nifi.processors.standard.GenerateTableFetch` | 5 (required 2) | failure, gen-table-column-for-val-partitioning, gen-table-custom-orderby-column, gen-table-fetch-partition-size, gen-table-output-flowfile-on-zero-results | Tags: sql, select, jdbc, query, database, fetch, generate; Stateful; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/GenerateTableFetch.java |  |
| `org.apache.nifi.processors.standard.GetFile` | 12 (required 9) | Batch Size, File Filter, Ignore Hidden Files, Input Directory, Keep Source File, Maximum File Age, Maximum File Size, Minimum File Age, Minimum File Size, Path Filter, Polling Interval, Recurse Subdirectories, success | Tags: local, files, filesystem, ingest, ingress, get, source, input; Restricted; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/GetFile.java | Creates FlowFiles from files in a directory.  NiFi will ignore files it doesn't have at least read permissions for. |
| `org.apache.nifi.processors.standard.GetFileResource` | 3 (required 1) | File Resource, MIME Type, success | Tags: test, file, generate, load; Restricted; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/GetFileResource.java |  |
| `org.apache.nifi.processors.standard.HandleHttpRequest` | 21 (required 16) | Additional HTTP Methods, Allow DELETE, Allow GET, Allow HEAD, Allow OPTIONS, Allow POST, Allow PUT, Allowed Paths, Client Authentication, Default URL Character Set, HTTP Context Map, HTTP Protocols, Hostname, Listening Port, Maximum Threads, Request Header Maximum Size, SSL Context Service, container-queue-size, multipart-read-buffer-size, multipart-request-max-size, parameters-to-attributes, success | Tags: http, https, request, listen, ingress, web service; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/HandleHttpRequest.java | Starts an HTTP Server and listens for HTTP Requests. For each request, creates a FlowFile and transfers to 'success'. This Processor is designed to be used in conjunction with the HandleHttpResponse Processor in order to create a Web Service. In case  of a multipart request, one FlowFile is generated for each part. |
| `org.apache.nifi.processors.standard.HandleHttpResponse` | 4 (required 2) | Attributes to add to the HTTP Response (Regex), HTTP Context Map, HTTP Status Code, failure, success | Tags: http, https, response, egress, web service; ReadsAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/HandleHttpResponse.java | Sends an HTTP Response to the Requestor that generated a FlowFile. This Processor is designed to be used in conjunction with the HandleHttpRequest in order to create a web service. |
| `org.apache.nifi.processors.standard.IdentifyMimeType` | 3 (required 3) | Custom MIME Configuration, config-strategy, success, use-filename-in-detection | Tags: compression, gzip, bzip2, zip, MIME, mime.type, file, identify; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/IdentifyMimeType.java | Attempts to identify the MIME Type used for a FlowFile. If the MIME Type can be identified, an attribute with the name 'mime.type' is added with the value being the MIME Type. If the MIME Type cannot be determined, the value will be set to 'application/octet-stream'. In addition, the attribute 'mime.extension' will be set if a common file extension for the MIME Type is known. If the MIME Type detected is of type text/*, attempts to identify the charset used and an attribute with the name 'mime.charset' is added with the value being the charset. |
| `org.apache.nifi.processors.standard.ListDatabaseTables` | 8 (required 3) | list-db-include-count, list-db-refresh-interval, list-db-tables-catalog, list-db-tables-db-connection, list-db-tables-name-pattern, list-db-tables-schema-pattern, list-db-tables-types, record-writer, success | Tags: sql, list, jdbc, table, database; Stateful; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/ListDatabaseTables.java | Generates a set of flow files, each containing attributes corresponding to metadata about a table from a database connection. Once metadata about a table has been fetched, it will not be fetched again until the Refresh Interval (if set) has elapsed, or until state has been manually cleared. |
| `org.apache.nifi.processors.standard.ListFile` | 1 (required 10) | File Filter, Ignore Hidden Files, Include File Attributes, Input Directory, Input Directory Location, Maximum File Age, Maximum File Size, Minimum File Age, Minimum File Size, Path Filter, Recurse Subdirectories, max-listing-time, max-operation-time, max-performance-metrics, track-performance | Tags: file, get, list, ingest, source, filesystem; Stateful; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/ListFile.java | Retrieves a listing of files from the input directory. For each file listed, creates a FlowFile that represents the file so that it can be fetched in conjunction with FetchFile. This Processor is designed to run on Primary Node only in a cluster when 'Input Directory Location' is set to 'Remote'. If the primary node changes, the new Primary Node will pick up where the previous node left off without duplicating all the data. When 'Input Directory Location' is 'Local', the 'Execution' mode can be anything, and synchronization won't happen. Unlike GetFile, this Processor does not delete any data from the local filesystem. |
| `org.apache.nifi.processors.standard.ListenFTP` | 5 (required 1) | Address, Password, Port, SSL Context Service, Username, success | Tags: ingest, FTP, FTPS, listen; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/ListenFTP.java | Starts an FTP server that listens on the specified port and transforms incoming files into FlowFiles. The URI of the service will be ftp://{hostname}:{port}. The default port is 2221. |
| `org.apache.nifi.processors.standard.ListenHTTP` | 17 (required 10) | Authorized DN Pattern, Base Path, HTTP Headers to receive as Attributes (Regex), HTTP Protocols, Listening Port, Max Unconfirmed Flowfile Time, Request Header Maximum Size, Return Code, SSL Context Service, authorized-issuer-dn-pattern, client-authentication, health-check-port, max-thread-pool-size, multipart-read-buffer-size, multipart-request-max-size, record-reader, record-writer, success | Tags: ingest, http, https, rest, listen | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/ListenHTTP.java |  |
| `org.apache.nifi.processors.standard.ListenSyslog` | 10 (required 8) | Client Auth, Max Batch Size, Max Size of Message Queue, Max Size of Socket Buffer, Message Delimiter, Parse Messages, Receive Buffer Size, SSL Context Service, Socket Keep Alive, Worker Threads, invalid, success | Tags: syslog, listen, udp, tcp, logs; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/ListenSyslog.java |  |
| `org.apache.nifi.processors.standard.ListenTCP` | 4 (required 3) | Client Auth, SSL Context Service, idle-timeout, pool-receive-buffers, success | Tags: listen, tcp, tls, ssl; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/ListenTCP.java | Listens for incoming TCP connections and reads data from each connection using a line separator as the message demarcator. The default behavior is for each message to produce a single FlowFile, however this can be controlled by increasing the Batch Size to a larger value for higher throughput. The Receive Buffer Size must be set as large as the largest messages expected to be received, meaning if every 100kb there is a line separator, then the Receive Buffer Size must be greater than 100kb. The processor can be configured to use an SSL Context Service to only allow secure connections. When connected clients present certificates for mutual TLS authentication, the Distinguished Names of the client certificate's issuer and subject are added to the outgoing FlowFiles as attributes. The processor does not perform authorization based on Distinguished Name values, but since these values are attached to the outgoing FlowFiles, authorization can be implemented based on these attributes. |
| `org.apache.nifi.processors.standard.ListenUDP` | 2 (required 0) | Sending Host, Sending Host Port | Tags: ingest, udp, listen, source; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/ListenUDP.java | Listens for Datagram Packets on a given port. The default behavior produces a FlowFile per datagram, however for higher throughput the Max Batch Size property may be increased to specify the number of datagrams to batch together in a single FlowFile. This processor can be restricted to listening for datagrams from  a specific remote host and port by specifying the Sending Host and Sending Host Port properties, otherwise it will listen for datagrams from all hosts and ports. |
| `org.apache.nifi.processors.standard.ListenUDPRecord` | 6 (required 4) | batch-size, parse.failure, poll-timeout, record-reader, record-writer, sending-host, sending-host-port | Tags: ingest, udp, listen, source, record; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/ListenUDPRecord.java | Listens for Datagram Packets on a given port and reads the content of each datagram using the configured Record Reader. Each record will then be written to a flow file using the configured Record Writer. This processor can be restricted to listening for datagrams from  a specific remote host and port by specifying the Sending Host and Sending Host Port properties, otherwise it will listen for datagrams from all hosts and ports. |
| `org.apache.nifi.processors.standard.LogAttribute` | 10 (required 5) | Attributes to Ignore, Attributes to Log, Log FlowFile Properties, Log Level, Log Payload, Log prefix, Output Format, attributes-to-ignore-regex, attributes-to-log-regex, character-set, success | Tags: attributes, logging | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/LogAttribute.java | Emits attributes of the FlowFile at the specified log level |
| `org.apache.nifi.processors.standard.LogMessage` | 3 (required 1) | log-level, log-message, log-prefix, success | Tags: attributes, logging | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/LogMessage.java | Emits a log message at the specified log level |
| `org.apache.nifi.processors.standard.LookupAttribute` | 3 (required 2) | failure, include-empty-values, lookup-service, matched, unmatched | Tags: lookup, cache, enrich, join, attributes, Attribute Expression Language | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/LookupAttribute.java | Lookup attributes from a lookup service |
| `org.apache.nifi.processors.standard.LookupRecord` | 10 (required 7) | Root Record Path, failure, lookup-service, matched, record-path-lookup-miss-result-cache-size, record-reader, record-update-strategy, record-writer, result-contents, result-record-path, routing-strategy, success, unmatched | Tags: lookup, enrichment, route, record, csv, json, avro, database, db, logs, convert, filter; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/LookupRecord.java |  |
| `org.apache.nifi.processors.standard.MergeRecord` | 10 (required 6) | correlation-attribute-name, failure, max-bin-age, max-bin-size, max-records, max.bin.count, merge-strategy, merged, min-bin-size, min-records, original, record-reader, record-writer | Tags: merge, record, content, correlation, stream, event; WritesAttributes; ReadsAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/MergeRecord.java | This Processor merges together multiple record-oriented FlowFiles into a single FlowFile that contains all of the Records of the input FlowFiles. This Processor works by creating 'bins' and then adding FlowFiles to these bins until they are full. Once a bin is full, all of the FlowFiles will be combined into a single output FlowFile, and that FlowFile will be routed to the 'merged' Relationship. A bin will consist of potentially many 'like FlowFiles'. In order for two FlowFiles to be considered 'like FlowFiles', they must have the same Schema (as identified by the Record Reader) and, if the <Correlation Attribute Name> property is set, the same value for the specified attribute. See Processor Usage and Additional Details for more information. NOTE: this processor should NOT be configured with Cron Driven for the Scheduling Strategy. |
| `org.apache.nifi.processors.standard.ModifyBytes` | 3 (required 3) | End Offset, Remove All Content, Start Offset, success | Tags: binary, discard, keep | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/ModifyBytes.java | Discard byte range at the start and end or all content of a binary file. |
| `org.apache.nifi.processors.standard.MonitorActivity` | 9 (required 9) | Activity Restored Message, Continually Send Messages, Copy Attributes, Inactivity Message, Monitoring Scope, Reporting Node, Reset State on Restart, Threshold Duration, Wait for Activity, activity.restored, inactive, success | Tags: monitor, flow, active, inactive, activity, detection; Stateful; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/MonitorActivity.java | Monitors the flow for activity and sends out an indicator when the flow has not had any data for some specified amount of time and again when the flow's activity is restored |
| `org.apache.nifi.processors.standard.Notify` | 6 (required 5) | attribute-cache-regex, distributed-cache-service, failure, release-signal-id, signal-buffer-count, signal-counter-delta, signal-counter-name, success | Tags: map, cache, notify, distributed, signal, release | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/Notify.java | Caches a release signal identifier in the distributed cache, optionally along with the FlowFile's attributes.  Any flow files held at a corresponding Wait processor will be released once this signal in the cache is discovered. |
| `org.apache.nifi.processors.standard.PackageFlowFile` | 2 (required 2) | Maximum Batch Content Size, max-batch-size, original, success | Tags: flowfile, flowfile-stream, flowfile-stream-v3, package, attributes; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/PackageFlowFile.java | This processor will package FlowFile attributes and content into an output FlowFile that can be exported from NiFi and imported back into NiFi, preserving the original attributes and content. |
| `org.apache.nifi.processors.standard.ParseSyslog` | 1 (required 1) | Character Set, failure, success | Tags: logs, syslog, attributes, system, event, message; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/ParseSyslog.java | Attempts to parses the contents of a Syslog message in accordance to RFC5424 and RFC3164 formats and adds attributes to the FlowFile for each of the parts of the Syslog message.Note: Be mindfull that RFC3164 is informational and a wide range of different implementations are present in the wild. If messages fail parsing, considering using RFC5424 or using a generic parsing processors such as ExtractGrok. |
| `org.apache.nifi.processors.standard.ParseSyslog5424` | 3 (required 2) | Character Set, failure, include_policy, nil_policy, success | Tags: logs, syslog, syslog5424, attributes, system, event, message; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/ParseSyslog5424.java | Attempts to parse the contents of a well formed Syslog message in accordance to RFC5424 format and adds attributes to the FlowFile for each of the parts of the Syslog message, including Structured Data.Structured Data will be written to attributes as one attribute per item id + parameter see https://tools.ietf.org/html/rfc5424.Note: ParseSyslog5424 follows the specification more closely than ParseSyslog.  If your Syslog producer does not follow the spec closely, with regards to using '-' for missing header entries for example, those logs will fail with this parser, where they would not fail with ParseSyslog. |
| `org.apache.nifi.processors.standard.PartitionRecord` | 3 (required 2) | failure, original, record-reader, record-writer, success | Tags: record, partition, recordpath, rpath, segment, split, group, bin, organize; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/PartitionRecord.java | Splits, or partitions, record-oriented data based on the configured fields in the data. One or more properties must be added. The name of the property is the name of an attribute to add. The value of the property is a RecordPath to evaluate against each Record. Two records will go to the same outbound FlowFile only if they have the same value for each of the given RecordPaths. Because we know that all records in a given output FlowFile have the same value for the fields that are specified by the RecordPath, an attribute is added for each field. See Additional Details on the Usage page for more information and examples. |
| `org.apache.nifi.processors.standard.PutDatabaseRecord` | 4 (required 11) | Column Name Translation Pattern, Column Name Translation Strategy, Data Record Path, Delete Keys, Statement Type Record Path, database-session-autocommit, failure, put-db-record-allow-multiple-statements, put-db-record-binary-format, put-db-record-catalog-name, put-db-record-dcbp-service, put-db-record-field-containing-sql, put-db-record-max-batch-size, put-db-record-query-timeout, put-db-record-quoted-identifiers, put-db-record-quoted-table-identifiers, put-db-record-record-reader, put-db-record-schema-name, put-db-record-statement-type, put-db-record-table-name, put-db-record-translate-field-names, put-db-record-unmatched-column-behavior, put-db-record-unmatched-field-behavior, put-db-record-update-keys, retry, success, table-schema-cache-size | Tags: sql, record, jdbc, put, database, update, insert, delete | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/PutDatabaseRecord.java | The PutDatabaseRecord processor uses a specified RecordReader to input (possibly multiple) records from an incoming flow file. These records are translated to SQL statements and executed as a single transaction. If any errors occur, the flow file is routed to failure or retry, and if the records are transmitted successfully, the incoming flow file is routed to success.  The type of statement executed by the processor is specified via the Statement Type property, which accepts some hard-coded values such as INSERT, UPDATE, and DELETE, as well as 'Use statement.type Attribute', which causes the processor to get the statement type from a flow file attribute.  IMPORTANT: If the Statement Type is UPDATE, then the incoming records must not alter the value(s) of the primary keys (or user-specified Update Keys). If such records are encountered, the UPDATE statement issued to the database may do nothing (if no existing records with the new primary key values are found), or could inadvertently corrupt the existing data (by changing records for which the new values of the primary keys exist). |
| `org.apache.nifi.processors.standard.PutDistributedMapCache` | 4 (required 3) | Cache Entry Identifier, Cache update strategy, Distributed Cache Service, Max cache entry size, failure, success | Tags: map, cache, put, distributed | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/PutDistributedMapCache.java | Gets the content of a FlowFile and puts it to a distributed map cache, using a cache key computed from FlowFile attributes. If the cache already contains the entry and the cache update strategy is 'keep original' the entry is not replaced.' |
| `org.apache.nifi.processors.standard.PutEmail` | 24 (required 15) | Attach File, BCC, CC, Content Type, From, Include All Attributes In Message, Message, Reply-To, SMTP Auth, SMTP Hostname, SMTP Password, SMTP Port, SMTP Socket Factory, SMTP TLS, SMTP Username, SMTP X-Mailer Header, Subject, To, attribute-name-regex, authorization-mode, email-ff-content-as-message, failure, input-character-set, oauth2-access-token-provider, success | Tags: email, put, notify, smtp | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/PutEmail.java | Sends an e-mail to configured recipients for each incoming FlowFile |
| `org.apache.nifi.processors.standard.PutFile` | 8 (required 3) | Conflict Resolution Strategy, Create Missing Directories, Directory, Group, Last Modified Time, Maximum File Count, Owner, Permissions, failure, success | Tags: put, local, copy, archive, files, filesystem; Restricted | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/PutFile.java | Writes the contents of a FlowFile to the local file system |
| `org.apache.nifi.processors.standard.PutRecord` | 3 (required 3) | failure, put-record-include-zero-record-results, put-record-reader, put-record-sink, retry, success | Tags: record, put, sink | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/PutRecord.java | The PutRecord processor uses a specified RecordReader to input (possibly multiple) records from an incoming flow file, and sends them to a destination specified by a Record Destination Service (i.e. record sink). |
| `org.apache.nifi.processors.standard.PutSQL` | 7 (required 2) | Batch Size, JDBC Connection Pool, Obtain Generated Keys, Support Fragmented Transactions, Transaction Timeout, database-session-autocommit, failure, putsql-sql-statement, retry, success | Tags: sql, put, rdbms, database, update, insert, relational; WritesAttributes; ReadsAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/PutSQL.java | Executes a SQL UPDATE or INSERT command. The content of an incoming FlowFile is expected to be the SQL command to execute. The SQL command may use the ? to escape parameters. In this case, the parameters to use must exist as FlowFile attributes with the naming convention sql.args.N.type and sql.args.N.value, where N is a positive integer. The sql.args.N.type is expected to be a number indicating the JDBC Type. The content of the FlowFile is expected to be in UTF-8 format. |
| `org.apache.nifi.processors.standard.PutSyslog` | 3 (required 8) | Batch Size, Hostname, Idle Connection Expiration, Max Size of Socket Send Buffer, Message Body, Message Hostname, Message Priority, Message Timestamp, Message Version, SSL Context Service, failure, invalid, success | Tags: syslog, put, udp, tcp, logs | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/PutSyslog.java |  |
| `org.apache.nifi.processors.standard.PutTCP` | 5 (required 3) | Record Reader, Record Writer, Transmission Strategy | Tags: remote, egress, put, tcp; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/PutTCP.java | Sends serialized FlowFiles or Records over TCP to a configurable destination with optional support for TLS |
| `org.apache.nifi.processors.standard.PutUDP` |  |  | Tags: remote, egress, put, udp | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/PutUDP.java | The PutUDP processor receives a FlowFile and packages the FlowFile content into a single UDP datagram packet which is then transmitted to the configured UDP server. The user must ensure that the FlowFile content being fed to this processor is not larger than the maximum size for the underlying UDP transport. The maximum transport size will vary based on the platform setup but is generally just under 64KB. FlowFiles will be marked as failed if their content is larger than the maximum transport size. |
| `org.apache.nifi.processors.standard.QueryRecord` | 4 (required 3) | failure, include-zero-record-flowfiles, original, record-reader, record-writer | Tags: sql, query, calcite, route, record, transform, select, update, modify, etl, filter, record, csv, json, logs, text, avro, aggregate; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/QueryRecord.java | Evaluates one or more SQL queries against the contents of a FlowFile. The result of the SQL query then becomes the content of the output FlowFile. This can be used, for example, for field-specific filtering, transformation, and row-level filtering. Columns can be renamed, simple calculations and aggregations performed, etc. The Processor is configured with a Record Reader Controller Service and a Record Writer service so as to allow flexibility in incoming and outgoing data formats. The Processor must be configured with at least one user-defined property. The name of the Property is the Relationship to route data to, and the value of the Property is a SQL SELECT statement that is used to specify how input data should be transformed/filtered. The SQL statement must be valid ANSI SQL and is powered by Apache Calcite. If the transformation fails, the original FlowFile is routed to the 'failure' relationship. Otherwise, the data selected will be routed to the associated relationship. If the Record Writer chooses to inherit the schema from the Record, it is important to note that the schema that is inherited will be from the ResultSet, rather than the input Record. This allows a single instance of the QueryRecord processor to have multiple queries, each of which returns a different set of columns and aggregations. As a result, though, the schema that is derived will have no schema name, so it is important that the configured Record Writer not attempt to write the Schema Name as an attribute if inheriting the Schema from the Record. See the Processor Usage documentation for more information. |
| `org.apache.nifi.processors.standard.RemoveRecordField` | 1 (required 0) |  | Tags: update, record, generic, schema, json, csv, avro, freeform, text, remove, delete; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/RemoveRecordField.java |  |
| `org.apache.nifi.processors.standard.RenameRecordField` | 1 (required 0) |  | Tags: update, record, rename, field, generic, schema, json, csv, avro, log, logs; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/RenameRecordField.java | Renames one or more fields in each Record of a FlowFile. This Processor requires that at least one user-defined Property be added. The name of the Property should indicate a RecordPath that determines the field that should be updated. The value of the Property is the new name to assign to the Record Field that matches the RecordPath. The property value may use Expression Language to reference FlowFile attributes as well as the variables `field.name`, `field.value`, `field.type`, and `record.index` |
| `org.apache.nifi.processors.standard.ReplaceText` | 9 (required 8) | Character Set, Evaluation Mode, Line-by-Line Evaluation Mode, Maximum Buffer Size, Regular Expression, Replacement Strategy, Replacement Value, Text to Append, Text to Prepend, failure, success | Tags: Text, Regular Expression, Update, Change, Replace, Modify, Regex | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/ReplaceText.java | Updates the content of a FlowFile by searching for some textual value in the FlowFile content (via Regular Expression/regex, or literal value) and replacing the section of the content that matches with some alternate value. It can also be used to append or prepend text to the contents of a FlowFile. |
| `org.apache.nifi.processors.standard.ReplaceTextWithMapping` | 6 (required 6) | Character Set, Mapping File, Mapping File Refresh Interval, Matching Group, Maximum Buffer Size, Regular Expression, failure, success | Tags: Text, Regular Expression, Update, Change, Replace, Modify, Regex, Mapping | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/ReplaceTextWithMapping.java | Updates the content of a FlowFile by evaluating a Regular Expression against it and replacing the section of the content that matches the Regular Expression with some alternate value provided in a mapping file. |
| `org.apache.nifi.processors.standard.RetryFlowFile` | 6 (required 5) | Fail on Non-numerical Overwrite, failure, maximum-retries, penalize-retries, retries_exceeded, retry, retry-attribute, reuse-mode | Tags: Retry, FlowFile; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/RetryFlowFile.java | FlowFiles passed to this Processor have a 'Retry Attribute' value checked against a configured 'Maximum Retries' value. If the current attribute value is below the configured maximum, the FlowFile is passed to a retry relationship. The FlowFile may or may not be penalized in that condition. If the FlowFile's attribute value exceeds the configured maximum, the FlowFile will be passed to a 'retries_exceeded' relationship. WARNING: If the incoming FlowFile has a non-numeric value in the configured 'Retry Attribute' attribute, it will be reset to '1'. You may choose to fail the FlowFile instead of performing the reset. Additional dynamic properties can be defined for any attributes you wish to add to the FlowFiles transferred to 'retries_exceeded'. These attributes support attribute expression language. |
| `org.apache.nifi.processors.standard.RouteOnAttribute` | 2 (required 1) | Routing Strategy, matched, unmatched | Tags: attributes, routing, Attribute Expression Language, regexp, regex, Regular Expression, Expression Language, find, text, string, search, filter, detect; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/RouteOnAttribute.java | Routes FlowFiles based on their Attributes using the Attribute Expression Language |
| `org.apache.nifi.processors.standard.RouteOnContent` | 4 (required 3) | Character Set, Content Buffer Size, Match Requirement, unmatched | Tags: route, content, regex, regular expression, regexp, find, text, string, search, filter, detect | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/RouteOnContent.java | Applies Regular Expressions to the content of a FlowFile and routes a copy of the FlowFile to each destination whose Regular Expression matches. Regular Expressions are added as User-Defined Properties where the name of the property is the name of the relationship and the value is a Regular Expression to match against the FlowFile content. User-Defined properties do support the Attribute Expression Language, but the results are interpreted as literal values, not Regular Expressions |
| `org.apache.nifi.processors.standard.RouteText` | 7 (required 5) | Character Set, Grouping Regular Expression, Ignore Case, Ignore Leading/Trailing Whitespace, Matching Strategy, Routing Strategy, matched, original, unmatched | Tags: attributes, routing, text, regexp, regex, Regular Expression, Expression Language, csv, filter, logs, delimited, find, string, search, filter, detect; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/RouteText.java | Routes textual data based on a set of user-defined rules. Each line in an incoming FlowFile is compared against the values specified by user-defined Properties. The mechanism by which the text is compared to these user-defined properties is defined by the 'Matching Strategy'. The data is then routed according to these rules, routing each line of the text individually. |
| `org.apache.nifi.processors.standard.SampleRecord` | 8 (required 7) | failure, original, record-reader, record-writer, sample-record-interval, sample-record-probability, sample-record-random-seed, sample-record-range, sample-record-reservoir, sample-record-sampling-strategy, success | Tags: record, sample, reservoir, range, interval; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/SampleRecord.java | Samples the records of a FlowFile based on a specified sampling strategy (such as Reservoir Sampling). The resulting FlowFile may be of a fixed number of records (in the case of reservoir-based algorithms) or some subset of the total number of records (in the case of probabilistic sampling), or a deterministic number of records (in the case of interval sampling). |
| `org.apache.nifi.processors.standard.ScanAttribute` | 4 (required 3) | Attribute Pattern, Dictionary File, Dictionary Filter Pattern, Match Criteria, matched, unmatched | Tags: scan, attributes, search, lookup, find, text | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/ScanAttribute.java | Scans the specified attributes of FlowFiles, checking to see if any of their values are present within the specified dictionary of terms |
| `org.apache.nifi.processors.standard.ScanContent` | 2 (required 2) | Dictionary Encoding, Dictionary File, matched, unmatched | Tags: aho-corasick, scan, content, byte sequence, search, find, dictionary | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/ScanContent.java | Scans the content of FlowFiles for terms that are found in a user-supplied dictionary. If a term is matched, the UTF-8 encoded version of the term will be added to the FlowFile using the 'matching.term' attribute |
| `org.apache.nifi.processors.standard.SegmentContent` | 1 (required 1) | Segment Size, original, segments | Tags: segment, split; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/SegmentContent.java | Segments a FlowFile into multiple smaller segments on byte boundaries. Each segment is given the following attributes: fragment.identifier, fragment.index, fragment.count, segment.original.filename; these attributes can then be used by the MergeContent processor in order to reconstitute the original FlowFile |
| `org.apache.nifi.processors.standard.SplitContent` | 4 (required 4) | Byte Sequence, Byte Sequence Format, Byte Sequence Location, Keep Byte Sequence, original, splits | Tags: content, split, binary; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/SplitContent.java | Splits incoming FlowFiles by a specified byte sequence |
| `org.apache.nifi.processors.standard.SplitJson` | 1 (required 1) | JsonPath Expression, failure, original, split | Tags: json, split, jsonpath; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/SplitJson.java | Splits a JSON File into multiple, separate FlowFiles for an array element specified by a JsonPath expression. Each generated FlowFile is comprised of an element of the specified array and transferred to relationship 'split,' with the original file transferred to the 'original' relationship. If the specified JsonPath is not found or does not evaluate to an array element, the original file is routed to 'failure' and no files are generated. |
| `org.apache.nifi.processors.standard.SplitRecord` | 3 (required 3) | Record Reader, Record Writer, Records Per Split, failure, original, splits | Tags: split, generic, schema, json, csv, avro, log, logs, freeform, text; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/SplitRecord.java | Splits up an input FlowFile that is in a record-oriented data format into multiple smaller FlowFiles |
| `org.apache.nifi.processors.standard.SplitText` | 5 (required 3) | Header Line Count, Header Line Marker Characters, Line Split Count, Maximum Fragment Size, Remove Trailing Newlines, failure, original, splits | Tags: split, text; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/SplitText.java | Splits a text file into multiple smaller text files on line boundaries limited by maximum number of lines or total size of fragment. Each output split file will contain no more than the configured number of lines or bytes. If both Line Split Count and Maximum Fragment Size are specified, the split occurs at whichever limit is reached first. If the first line of a fragment exceeds the Maximum Fragment Size, that line will be output in a single split file which exceeds the configured maximum size limit. This component also allows one to specify that each split should include a header lines. Header lines can be computed by either specifying the amount of lines that should constitute a header or by using header marker to match against the read lines. If such match happens then the corresponding line will be treated as header. Keep in mind that upon the first failure of header marker match, no more matches will be performed and the rest of the data will be parsed as regular lines for a given split. If after computation of the header there are no more data, the resulting split will consists of only header lines. |
| `org.apache.nifi.processors.standard.SplitXml` | 1 (required 1) | Split Depth, failure, original, split | Tags: xml, split; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/SplitXml.java | Splits an XML File into multiple separate FlowFiles, each comprising a child or descendant of the original root element |
| `org.apache.nifi.processors.standard.TailFile` | 1 (required 7) | File Location, File to Tail, Initial Start Position, Line Start Pattern, Max Buffer Size, Post-Rollover Tail Period, Rolling Filename Pattern, pre-allocated-buffer-size, reread-on-nul, success, tail-base-directory, tail-mode, tailfile-lookup-frequency, tailfile-maximum-age, tailfile-recursive-lookup | Tags: tail, file, log, text, source; Restricted; Stateful | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/TailFile.java |  |
| `org.apache.nifi.processors.standard.TransformXml` | 8 (required 4) | XSLT file name, cache-size, cache-ttl-after-last-access, failure, indent-output, secure-processing, success, xslt-controller, xslt-controller-key | Tags: xml, xslt, transform | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/TransformXml.java | Applies the provided XSLT file to the FlowFile XML payload. A new FlowFile is created with transformed content and is routed to the 'success' relationship. If the XSL transform fails, the original FlowFile is routed to the 'failure' relationship |
| `org.apache.nifi.processors.standard.UnpackContent` | 5 (required 4) | File Filter, Filename Character Set, Packaging Format, Password, allow-stored-entries-wdd, failure, original, success | Tags: Unpack, un-merge, tar, zip, archive, flowfile-stream, flowfile-stream-v3; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/UnpackContent.java | Unpacks the content of FlowFiles that have been packaged with one of several different Packaging Formats, emitting one to many FlowFiles for each input FlowFile. Supported formats are TAR, ZIP, and FlowFile Stream packages. |
| `org.apache.nifi.processors.standard.UpdateCounter` | 2 (required 2) | counter-name, delta, success | Tags: counter, debug, instrumentation | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/UpdateCounter.java | This processor allows users to set specific counters and key points in their flow. It is useful for debugging and basic counting functions. |
| `org.apache.nifi.processors.standard.UpdateDatabaseTable` | 15 (required 10) | Column Name Translation Pattern, Column Name Translation Strategy, failure, record-reader, success, updatedatabasetable-catalog-name, updatedatabasetable-create-table, updatedatabasetable-dbcp-service, updatedatabasetable-primary-keys, updatedatabasetable-query-timeout, updatedatabasetable-quoted-column-identifiers, updatedatabasetable-quoted-table-identifiers, updatedatabasetable-record-writer, updatedatabasetable-schema-name, updatedatabasetable-table-name, updatedatabasetable-translate-field-names, updatedatabasetable-update-field-names | Tags: metadata, jdbc, database, table, update, alter; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/UpdateDatabaseTable.java | This processor uses a JDBC connection and incoming records to generate any database table changes needed to support the incoming records. It expects a 'flat' record layout, meaning none of the top-level record fields has nested fields that are intended to become columns themselves. |
| `org.apache.nifi.processors.standard.UpdateRecord` | 2 (required 1) | Replacement Value Strategy | Tags: update, record, generic, schema, json, csv, avro, log, logs, freeform, text; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/UpdateRecord.java | Updates the contents of a FlowFile that contains Record-oriented data (i.e., data that can be read via a RecordReader and written by a RecordWriter). This Processor requires that at least one user-defined Property be added. The name of the Property should indicate a RecordPath that determines the field that should be updated. The value of the Property is either a replacement value (optionally making use of the Expression Language) or is itself a RecordPath that extracts a value from the Record. Whether the Property value is determined to be a RecordPath or a literal value depends on the configuration of the <Replacement Value Strategy> Property. |
| `org.apache.nifi.processors.standard.ValidateCsv` | 9 (required 7) | CSV Source Attribute, Max Lines Per Row, invalid, valid, validate-csv-delimiter, validate-csv-eol, validate-csv-header, validate-csv-quote, validate-csv-schema, validate-csv-strategy, validate-csv-violations | Tags: csv, schema, validation; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/ValidateCsv.java | Validates the contents of FlowFiles or a FlowFile attribute value against a user-specified CSV schema. Take a look at the additional documentation of this processor for some schema examples. |
| `org.apache.nifi.processors.standard.ValidateJson` | 6 (required 5) | JSON Schema Registry, Max String Length, Schema Access Strategy, failure, invalid, valid | Tags: JSON, schema, validation; Restricted; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/ValidateJson.java |  |
| `org.apache.nifi.processors.standard.ValidateRecord` | 9 (required 6) | allow-extra-fields, coerce-types, failure, invalid, invalid-record-writer, maximum-validation-details-length, record-reader, record-writer, strict-type-checking, valid, validation-details-attribute-name | Tags: record, schema, validate; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/ValidateRecord.java |  |
| `org.apache.nifi.processors.standard.ValidateXml` | 2 (required 0) | Schema File, XML Source Attribute, invalid, valid | Tags: xml, schema, validation, xsd; Restricted; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/ValidateXml.java | Validates XML contained in a FlowFile. By default, the XML is contained in the FlowFile content. If the 'XML Source Attribute' property is set, the XML to be validated is contained in the specified attribute. It is not recommended to use attributes to hold large XML documents; doing so could adversely affect system performance. Full schema validation is performed if the processor is configured with the XSD schema details. Otherwise, the only validation performed is to ensure the XML syntax is correct and well-formed, e.g. all opening tags are properly closed. |
| `org.apache.nifi.processors.standard.Wait` | 10 (required 8) | attribute-copy-mode, distributed-cache-service, expiration-duration, expired, failure, releasable-flowfile-count, release-signal-id, signal-counter-name, success, target-signal-count, wait, wait-buffer-count, wait-mode, wait-penalty-duration | Tags: map, cache, wait, hold, distributed, signal, release; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/Wait.java |  |
| `org.apache.nifi.processors.standard.for` | 7 (required 3) | Columns to Return, Database Connection Pooling Service, Max Wait Time, Maximum-value Columns, Table Name, db-fetch-sql-query, db-fetch-where-clause, success |  | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/AbstractDatabaseFetchProcessor.java |  |
| `org.apache.nifi.processors.standard.raised` | 37 (required 20) | Connection Timeout, Failure, HTTP Method, HTTP URL, HTTP/2 Disabled, No Retry, OAuth2 Access Token Refresh Strategy, Original, Request Body Enabled, Request Chunked Transfer-Encoding Enabled, Request Content-Encoding, Request Content-Type, Request Date Header Enabled, Request Digest Authentication Enabled, Request Failure Penalization Enabled, Request Header Attributes Pattern, Request Multipart Form-Data Filename Enabled, Request Multipart Form-Data Name, Request OAuth2 Access Token Provider, Request Password, Request User-Agent, Request Username, Response, Response Body Attribute Name, Response Body Attribute Size, Response Body Ignored, Response Cache Enabled, Response Cache Size, Response Cookie Strategy, Response FlowFile Naming Strategy, Response Generation Required, Response Header Request Attributes Enabled, Response Header Request Attributes Prefix, Response Redirects Enabled, Retry, SSL Context Service, Socket Idle Connections, Socket Idle Timeout, Socket Read Timeout, Socket Write Timeout | Tags: http, https, rest, client; WritesAttributes | nifi-extension-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/InvokeHTTP.java | An HTTP client processor which can interact with a configurable HTTP Endpoint. The destination URL and HTTP Method are configurable. When the HTTP Method is PUT, POST or PATCH, the FlowFile contents are included as the body of the request and FlowFile attributes are converted to HTTP headers, optionally, based on configuration properties. |
| `org.apache.nifi.processors.stateful.analysis.AttributeRollingWindow` | 3 (required 2) | Sub-window length, Time window, Value to track, failure, set state fail, success | Tags: Attribute Expression Language, state, data science, rolling, window; Stateful; WritesAttributes | nifi-extension-bundles/nifi-stateful-analysis-bundle/nifi-stateful-analysis-processors/src/main/java/org/apache/nifi/processors/stateful/analysis/AttributeRollingWindow.java | Track a Rolling Window based on evaluating an Expression Language expression on each FlowFile and add that value to the processor's state. Each FlowFile will be emitted with the count of FlowFiles and total aggregate value of values processed in the current time window. |
| `org.apache.nifi.processors.tests.system.ClassloaderIsolationWithServiceProperty` | 1 (required 0) | Key Provider Service, success |  | nifi-system-tests/nifi-system-test-extensions-bundle/nifi-system-test-extensions/src/main/java/org/apache/nifi/processors/tests/system/ClassloaderIsolationWithServiceProperty.java |  |
| `org.apache.nifi.processors.tests.system.ConcatenateFlowFiles` | 1 (required 1) | FlowFile Count, merged, original |  | nifi-system-tests/nifi-system-test-extensions-bundle/nifi-system-test-extensions/src/main/java/org/apache/nifi/processors/tests/system/ConcatenateFlowFiles.java |  |
| `org.apache.nifi.processors.tests.system.CountEvents` | 1 (required 0) | Name, Sensitive |  | nifi-system-tests/nifi-system-test-extensions-bundle/nifi-system-test-extensions/src/main/java/org/apache/nifi/processors/tests/system/CountEvents.java |  |
| `org.apache.nifi.processors.tests.system.CountFlowFiles` | 1 (required 1) | Count Service, success |  | nifi-system-tests/nifi-system-test-extensions-bundle/nifi-system-test-extensions/src/main/java/org/apache/nifi/processors/tests/system/CountFlowFiles.java |  |
| `org.apache.nifi.processors.tests.system.CountPrimaryNodeChangeEvents` | 1 (required 1) | Event Sleep Duration |  | nifi-system-tests/nifi-system-test-extensions-bundle/nifi-system-test-extensions/src/main/java/org/apache/nifi/processors/tests/system/CountPrimaryNodeChangeEvents.java |  |
| `org.apache.nifi.processors.tests.system.DefaultedDynamicallyModifyClasspath` | 2 (required 1) | Class to Load, URLs to Load, failure, success |  | nifi-system-tests/nifi-system-test-extensions-bundle/nifi-system-test-extensions/src/main/java/org/apache/nifi/processors/tests/system/DefaultedDynamicallyModifyClasspath.java |  |
| `org.apache.nifi.processors.tests.system.DependOnProperties` | 1 (required 5) | Always Optional, Always Required, Multiple Dependencies, Required If Always Required Is Bar Or Baz, Required If Optional Property Set, Required If Optional Property Set To Foo, Second Level Dependency |  | nifi-system-tests/nifi-system-test-extensions-bundle/nifi-system-test-extensions/src/main/java/org/apache/nifi/processors/tests/system/DependOnProperties.java |  |
| `org.apache.nifi.processors.tests.system.DoNotTransferFlowFile` |  |  |  | nifi-system-tests/nifi-system-test-extensions-bundle/nifi-system-test-extensions/src/main/java/org/apache/nifi/processors/tests/system/DoNotTransferFlowFile.java | Pulls FlowFile from queue and ignores it, intentionally neglecting to transfer it to any relationship. This is intended for verifying behavior in System Tests only |
| `org.apache.nifi.processors.tests.system.Duplicate` | 1 (required 1) | Output Count, success |  | nifi-system-tests/nifi-system-test-extensions-bundle/nifi-system-test-extensions/src/main/java/org/apache/nifi/processors/tests/system/Duplicate.java |  |
| `org.apache.nifi.processors.tests.system.DynamicallyModifyClasspath` | 3 (required 1) | Class to Load, Sleep Duration, URLs to Load, failure, success |  | nifi-system-tests/nifi-system-test-extensions-bundle/nifi-system-test-extensions/src/main/java/org/apache/nifi/processors/tests/system/DynamicallyModifyClasspath.java |  |
| `org.apache.nifi.processors.tests.system.EnsureProcessorConfigurationCorrect` | 1 (required 3) | Exception on Verification, Failure Node Number, Successful Verification, Verification Steps |  | nifi-system-tests/nifi-system-test-extensions-bundle/nifi-system-test-extensions/src/main/java/org/apache/nifi/processors/tests/system/EnsureProcessorConfigurationCorrect.java |  |
| `org.apache.nifi.processors.tests.system.EvaluatePropertiesWithDifferentELScopes` | 3 (required 0) | Expression Language Not Evaluated, FlowFile Context, Variable Registry Context, success |  | nifi-system-tests/nifi-system-test-extensions-bundle/nifi-system-test-extensions/src/main/java/org/apache/nifi/processors/tests/system/EvaluatePropertiesWithDifferentELScopes.java |  |
| `org.apache.nifi.processors.tests.system.GenerateAndCountCallbacks` |  | success |  | nifi-system-tests/nifi-system-test-extensions-bundle/nifi-system-test-extensions/src/main/java/org/apache/nifi/processors/tests/system/GenerateAndCountCallbacks.java | Generates an empty FlowFile and counts how many times the session commit callback is called for both success and failure before and after Processor is stopped |
| `org.apache.nifi.processors.tests.system.GenerateFlowFile` | 1 (required 2) | Batch Size, File Size, File to Write on Commit Failure, Max FlowFiles, State Scope, Text, success | Stateful | nifi-system-tests/nifi-system-test-extensions-bundle/nifi-system-test-extensions/src/main/java/org/apache/nifi/processors/tests/system/GenerateFlowFile.java |  |
| `org.apache.nifi.processors.tests.system.HoldInput` | 1 (required 1) | Hold Time, success |  | nifi-system-tests/nifi-system-test-extensions-bundle/nifi-system-test-extensions/src/main/java/org/apache/nifi/processors/tests/system/HoldInput.java |  |
| `org.apache.nifi.processors.tests.system.IngestFile` | 2 (required 2) | Commit Mode, Delete File, Filename, success |  | nifi-system-tests/nifi-system-test-extensions-bundle/nifi-system-test-extensions/src/main/java/org/apache/nifi/processors/tests/system/IngestFile.java |  |
| `org.apache.nifi.processors.tests.system.LoopFlowFile` | 1 (required 1) | Count, finished, loop |  | nifi-system-tests/nifi-system-test-extensions-bundle/nifi-system-test-extensions/src/main/java/org/apache/nifi/processors/tests/system/LoopFlowFile.java |  |
| `org.apache.nifi.processors.tests.system.MigrateProperties` | 4 (required 2) | attr-to-add, attr-value, failure, ignored, ingest-data, success |  | nifi-system-tests/nifi-system-test-extensions-bundle/nifi-system-test-extensions/src/main/java/org/apache/nifi/processors/tests/system/MigrateProperties.java |  |
| `org.apache.nifi.processors.tests.system.MultiKeyState` |  | success | Stateful | nifi-system-tests/nifi-system-test-extensions-bundle/nifi-system-test-extensions/src/main/java/org/apache/nifi/processors/tests/system/MultiKeyState.java |  |
| `org.apache.nifi.processors.tests.system.MultiKeyStateNotDroppable` |  | success | Stateful | nifi-system-tests/nifi-system-test-extensions-bundle/nifi-system-test-extensions/src/main/java/org/apache/nifi/processors/tests/system/MultiKeyStateNotDroppable.java |  |
| `org.apache.nifi.processors.tests.system.PartitionText` | 1 (required 1) | Number of Output FlowFiles, success |  | nifi-system-tests/nifi-system-test-extensions-bundle/nifi-system-test-extensions/src/main/java/org/apache/nifi/processors/tests/system/PartitionText.java |  |
| `org.apache.nifi.processors.tests.system.PassThrough` |  | success |  | nifi-system-tests/nifi-system-test-extensions-bundle/nifi-system-test-extensions/src/main/java/org/apache/nifi/processors/tests/system/PassThrough.java |  |
| `org.apache.nifi.processors.tests.system.PassThroughRequiresInstanceClassLoading` |  | success |  | nifi-system-tests/nifi-system-test-extensions-bundle/nifi-system-test-extensions/src/main/java/org/apache/nifi/processors/tests/system/PassThroughRequiresInstanceClassLoading.java |  |
| `org.apache.nifi.processors.tests.system.ReOrderFlowFiles` | 1 (required 1) | First Group Selection Criteria, success |  | nifi-system-tests/nifi-system-test-extensions-bundle/nifi-system-test-extensions/src/main/java/org/apache/nifi/processors/tests/system/ReOrderFlowFiles.java | Selects FlowFiles that match the given criteria and transfers them to the 'success' relationship. Then, selects all other FlowFiles and transfers them to the success relationship. Note that this Processor will not work properly if it is scheduled to run while its incoming queue(s) are being populated. This is meant to be used only for purposes of testing in a Stateless execution engine and makes use of FlowFileFilters. |
| `org.apache.nifi.processors.tests.system.ReplaceWithFile` | 1 (required 1) | Filename, success |  | nifi-system-tests/nifi-system-test-extensions-bundle/nifi-system-test-extensions/src/main/java/org/apache/nifi/processors/tests/system/ReplaceWithFile.java |  |
| `org.apache.nifi.processors.tests.system.ReverseContents` |  | success |  | nifi-system-tests/nifi-system-test-extensions-bundle/nifi-system-test-extensions/src/main/java/org/apache/nifi/processors/tests/system/ReverseContents.java |  |
| `org.apache.nifi.processors.tests.system.RoundRobinFlowFiles` | 1 (required 1) | Number of Relationships |  | nifi-system-tests/nifi-system-test-extensions-bundle/nifi-system-test-extensions/src/main/java/org/apache/nifi/processors/tests/system/RoundRobinFlowFiles.java |  |
| `org.apache.nifi.processors.tests.system.SensitiveDynamicPropertiesProcessor` | 1 (required 0) |  |  | nifi-system-tests/nifi-system-test-extensions-bundle/nifi-system-test-extensions/src/main/java/org/apache/nifi/processors/tests/system/SensitiveDynamicPropertiesProcessor.java |  |
| `org.apache.nifi.processors.tests.system.SetAttribute` | 1 (required 0) | success |  | nifi-system-tests/nifi-system-test-extensions-bundle/nifi-system-test-extensions/src/main/java/org/apache/nifi/processors/tests/system/SetAttribute.java |  |
| `org.apache.nifi.processors.tests.system.Sleep` | 1 (required 1) | @OnScheduled Sleep Time, @OnStopped Sleep Time, Ignore Interrupts, Sleep Service, Stop Sleeping When Unscheduled, Validate Sleep Time, onTrigger Sleep Time, success |  | nifi-system-tests/nifi-system-test-extensions-bundle/nifi-system-test-extensions/src/main/java/org/apache/nifi/processors/tests/system/Sleep.java |  |
| `org.apache.nifi.processors.tests.system.SplitByLine` | 1 (required 1) | Use Clone, success |  | nifi-system-tests/nifi-system-test-extensions-bundle/nifi-system-test-extensions/src/main/java/org/apache/nifi/processors/tests/system/SplitByLine.java |  |
| `org.apache.nifi.processors.tests.system.SplitTextByLine` |  | failure, original, splits |  | nifi-system-tests/nifi-system-test-extensions-bundle/nifi-system-test-extensions/src/main/java/org/apache/nifi/processors/tests/system/SplitTextByLine.java |  |
| `org.apache.nifi.processors.tests.system.TerminateFlowFile` |  |  |  | nifi-system-tests/nifi-system-test-extensions-bundle/nifi-system-test-extensions/src/main/java/org/apache/nifi/processors/tests/system/TerminateFlowFile.java |  |
| `org.apache.nifi.processors.tests.system.ThrowExceptionInFlowFileFilter` | 1 (required 1) | Throw Exception, success |  | nifi-system-tests/nifi-system-test-extensions-bundle/nifi-system-test-extensions/src/main/java/org/apache/nifi/processors/tests/system/ThrowExceptionInFlowFileFilter.java |  |
| `org.apache.nifi.processors.tests.system.ThrowProcessException` | 1 (required 1) | Text |  | nifi-system-tests/nifi-system-test-extensions-bundle/nifi-system-test-extensions/src/main/java/org/apache/nifi/processors/tests/system/ThrowProcessException.java |  |
| `org.apache.nifi.processors.tests.system.TransferBatch` | 1 (required 2) | Batch Size, Insufficient Batch Size Strategy, failure, success |  | nifi-system-tests/nifi-system-test-extensions-bundle/nifi-system-test-extensions/src/main/java/org/apache/nifi/processors/tests/system/TransferBatch.java |  |
| `org.apache.nifi.processors.tests.system.UnzipFlowFile` |  | failure, original, unzipped |  | nifi-system-tests/nifi-system-test-extensions-bundle/nifi-system-test-extensions/src/main/java/org/apache/nifi/processors/tests/system/UnzipFlowFile.java |  |
| `org.apache.nifi.processors.tests.system.UpdateContent` | 1 (required 2) | Content, Update Strategy, success |  | nifi-system-tests/nifi-system-test-extensions-bundle/nifi-system-test-extensions/src/main/java/org/apache/nifi/processors/tests/system/UpdateContent.java |  |
| `org.apache.nifi.processors.tests.system.ValidateFileExists` | 1 (required 1) | Filename, success |  | nifi-system-tests/nifi-system-test-extensions-bundle/nifi-system-test-extensions/src/main/java/org/apache/nifi/processors/tests/system/ValidateFileExists.java |  |
| `org.apache.nifi.processors.tests.system.VerifyContents` | 1 (required 0) | unmatched |  | nifi-system-tests/nifi-system-test-extensions-bundle/nifi-system-test-extensions/src/main/java/org/apache/nifi/processors/tests/system/VerifyContents.java |  |
| `org.apache.nifi.processors.tests.system.VerifyEvenThenOdd` | 1 (required 1) | Attribute Name, failure, success |  | nifi-system-tests/nifi-system-test-extensions-bundle/nifi-system-test-extensions/src/main/java/org/apache/nifi/processors/tests/system/VerifyEvenThenOdd.java | Ensures that all FlowFiles that are in the Processor's incoming queue are ordered such that the value of the key attribute is even for all FlowFiles before the first FlowFile with an odd value. If the FlowFiles are ordered correctly, they are transferred to the 'success' relationship; otherwise, they are transferred to the 'failure' relationship. The name of the key attribute is configurable. This is used to ensure that data is properly ordered while running within a Stateless flow. |
| `org.apache.nifi.processors.tests.system.WriteFlowFileCountToFile` | 1 (required 2) | Class to Create, File to Write, Isolation Key, failure, success |  | nifi-system-tests/nifi-system-test-extensions-bundle/nifi-system-test-extensions/src/main/java/org/apache/nifi/processors/tests/system/WriteFlowFileCountToFile.java |  |
| `org.apache.nifi.processors.tests.system.WriteLifecycleEvents` | 1 (required 1) | Event File, success |  | nifi-system-tests/nifi-system-test-extensions-bundle/nifi-system-test-extensions/src/main/java/org/apache/nifi/processors/tests/system/WriteLifecycleEvents.java |  |
| `org.apache.nifi.processors.tests.system.WriteToFile` | 1 (required 1) | Filename, failure, success |  | nifi-system-tests/nifi-system-test-extensions-bundle/nifi-system-test-extensions/src/main/java/org/apache/nifi/processors/tests/system/WriteToFile.java |  |
| `org.apache.nifi.processors.tests.system.YieldSource` | 1 (required 1) | Yield After, success |  | nifi-system-tests/nifi-system-test-extensions-bundle/nifi-system-test-extensions/src/main/java/org/apache/nifi/processors/tests/system/YieldSource.java |  |
| `org.apache.nifi.processors.twitter.ConsumeTwitter` | 17 (required 11) | backfill-minutes, backoff-attempts, backoff-time, base-path, batch-size, bearer-token, connect-timeout, expansions, maximum-backoff-time, media-fields, place-fields, poll-fields, queue-size, read-timeout, stream-endpoint, success, tweet-fields, user-fields | Tags: twitter, tweets, social media, status, json; WritesAttributes | nifi-extension-bundles/nifi-social-media-bundle/nifi-twitter-processors/src/main/java/org/apache/nifi/processors/twitter/ConsumeTwitter.java | Streams tweets from Twitter's streaming API v2. The stream provides a sample stream or a search stream based on previously uploaded rules. This processor also provides a pass through for certain fields of the tweet to be returned as part of the response. See https://developer.twitter.com/en/docs/twitter-api/data-dictionary/introduction for more information regarding the Tweet object model. |
| `org.apache.nifi.processors.websocket.AbstractWebSocketGatewayProcessor` |  | binary message, connected, disconnected, failure, success, text message |  | nifi-extension-bundles/nifi-websocket-bundle/nifi-websocket-processors/src/main/java/org/apache/nifi/processors/websocket/AbstractWebSocketGatewayProcessor.java |  |
| `org.apache.nifi.processors.websocket.ConnectWebSocket` | 2 (required 2) | websocket-client-controller-service, websocket-client-id | Tags: subscribe, WebSocket, consume, listen; WritesAttributes | nifi-extension-bundles/nifi-websocket-bundle/nifi-websocket-processors/src/main/java/org/apache/nifi/processors/websocket/ConnectWebSocket.java | Acts as a WebSocket client endpoint to interact with a remote WebSocket server. FlowFiles are transferred to downstream relationships according to received message types as WebSocket client configured with this processor receives messages from remote WebSocket server. If a new flowfile is passed to the processor, the previous sessions will be closed and any data being sent will be aborted. |
| `org.apache.nifi.processors.websocket.ListenWebSocket` | 2 (required 2) | server-url-path, websocket-server-controller-service | Tags: subscribe, WebSocket, consume, listen; WritesAttributes | nifi-extension-bundles/nifi-websocket-bundle/nifi-websocket-processors/src/main/java/org/apache/nifi/processors/websocket/ListenWebSocket.java | Acts as a WebSocket server endpoint to accept client connections. FlowFiles are transferred to downstream relationships according to received message types as the WebSocket server configured with this processor receives client requests |
| `org.apache.nifi.processors.websocket.PutWebSocket` | 4 (required 4) | failure, success, websocket-controller-service-id, websocket-endpoint-id, websocket-message-type, websocket-session-id | Tags: WebSocket, publish, send; WritesAttributes | nifi-extension-bundles/nifi-websocket-bundle/nifi-websocket-processors/src/main/java/org/apache/nifi/processors/websocket/PutWebSocket.java | Sends messages to a WebSocket remote endpoint using a WebSocket session that is established by either ListenWebSocket or ConnectWebSocket. |
| `org.apache.nifi.processors.windows.event.log.ConsumeWindowsEventLog` | 5 (required 5) | channel, inactiveDurationToReconnect, maxBuffer, maxQueue, query, success | Tags: ingest, event, windows; WritesAttributes | nifi-extension-bundles/nifi-windows-event-log-bundle/nifi-windows-event-log-processors/src/main/java/org/apache/nifi/processors/windows/event/log/ConsumeWindowsEventLog.java | Registers a Windows Event Log Subscribe Callback to receive FlowFiles from Events on Windows.  These can be filtered via channel and XPath. |
| `org.apache.nifi.processors.workday.raised` | 8 (required 7) | Access Token Provider, Authorization Type, Web Client Service Provider, Workday Password, Workday Report URL, Workday Username, failure, original, record-reader, record-writer, success | Tags: Workday, report; WritesAttributes | nifi-extension-bundles/nifi-workday-bundle/nifi-workday-processors/src/main/java/org/apache/nifi/processors/workday/GetWorkdayReport.java | A processor which can interact with a configurable Workday Report. The processor can forward the content without modification, or you can transform it by providing the specific Record Reader and Record Writer services based on your needs. You can also remove fields by defining schema in the Record Writer. Supported Workday report formats are: csv, simplexml, json |
| `org.apache.nifi.processors.zendesk.AbstractZendesk` |  | success |  | nifi-extension-bundles/nifi-zendesk-bundle/nifi-zendesk-processors/src/main/java/org/apache/nifi/processors/zendesk/AbstractZendesk.java |  |
| `org.apache.nifi.redis.processor.PutRedisHashRecord` | 4 (required 4) | charset, data-record-path, failure, hash-value-record-path, record-reader, success | Tags: put, redis, hash, record; WritesAttributes | nifi-extension-bundles/nifi-redis-bundle/nifi-redis-extensions/src/main/java/org/apache/nifi/redis/processor/PutRedisHashRecord.java | Puts record field data into Redis using a specified hash value, which is determined by a RecordPath to a field in each record containing the hash value. The record fields and values are stored as key/value pairs associated by the hash value. NOTE: Neither the evaluated hash value nor any of the field values can be null. If the hash value is null, the FlowFile will be routed to failure. For each of the field values, if the value is null that field will be not set in Redis. |
| `org.apache.nifi.snmp.processors.AbstractSNMPProcessor` | 2 (required 2) | snmp-hostname, snmp-port |  | nifi-extension-bundles/nifi-snmp-bundle/nifi-snmp-processors/src/main/java/org/apache/nifi/snmp/processors/AbstractSNMPProcessor.java |  |
| `org.apache.nifi.snmp.processors.GetSNMP` | 3 (required 1) | failure, snmp-oid, snmp-strategy, snmp-textual-oid, success | Tags: snmp, get, oid, walk; WritesAttributes | nifi-extension-bundles/nifi-snmp-bundle/nifi-snmp-processors/src/main/java/org/apache/nifi/snmp/processors/GetSNMP.java | Retrieves information from SNMP Agent with SNMP Get request and outputs a FlowFile with information in attributes and without any content |
| `org.apache.nifi.snmp.processors.ListenTrapSNMP` | 5 (required 2) | failure, snmp-manager-port, snmp-usm-security-names, snmp-usm-users-file-path, snmp-usm-users-json-content, snmp-usm-users-source, success | Tags: snmp, listen, trap | nifi-extension-bundles/nifi-snmp-bundle/nifi-snmp-processors/src/main/java/org/apache/nifi/snmp/processors/ListenTrapSNMP.java | Receives information from SNMP Agent and outputs a FlowFile with information in attributes and without any content |
| `org.apache.nifi.snmp.processors.SendTrapSNMP` | 2 (required 2) | failure, snmp-trap-manager-host, snmp-trap-manager-port, success | Tags: snmp, send, trap | nifi-extension-bundles/nifi-snmp-bundle/nifi-snmp-processors/src/main/java/org/apache/nifi/snmp/processors/SendTrapSNMP.java | Sends information to SNMP Manager. |
| `org.apache.nifi.snmp.processors.SetSNMP` |  | failure, success | Tags: snmp, set, oid; WritesAttributes | nifi-extension-bundles/nifi-snmp-bundle/nifi-snmp-processors/src/main/java/org/apache/nifi/snmp/processors/SetSNMP.java | Based on incoming FlowFile attributes, the processor will execute SNMP Set requests. When finding attributes with the name snmp$<OID>, the processor will attempt to set the value of the attribute to the corresponding OID given in the attribute name. |

> Auto-generated from NiFi source; update scripts as needed.
